{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.0.0\n",
      "torchvision verseion: 0.2.1\n",
      "Is GPU avaibale: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('torchvision verseion:', torchvision.__version__)\n",
    "print('Is GPU avaibale:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings (バッチサイズとデバイス)\n",
    "batchsize = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of training data: 60000\n",
      "the number of validation data: 10000\n"
     ]
    }
   ],
   "source": [
    "# データセットの準備\n",
    "# Tensorにしつつ、 (-1 ~ 1)の範囲に正規化\n",
    "\n",
    "#def preprocess(tensor):\n",
    "#    return tensor - 0.5\n",
    "\n",
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# データセットをロード(今回はMNIST)\n",
    "# 本当はtraining data, validation data, test dataに分けるべきだが、今回は簡便のため2つに分ける.\n",
    "mnist_train = datasets.MNIST(root = '../../data/MNIST',\n",
    "                                 train = True,\n",
    "                                 transform = tf,\n",
    "                                 download = False)\n",
    "mnist_validation = datasets.MNIST(root = '../../data/MNIST',\n",
    "                                      train = False,\n",
    "                                      transform = tf)\n",
    "\n",
    "# データローダーを作成\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size = batchsize, shuffle = True)\n",
    "mnist_validation_loader = DataLoader(mnist_validation, batch_size = batchsize, shuffle = False)\n",
    "\n",
    "print('the number of training data:', len(mnist_train))\n",
    "print('the number of validation data:', len(mnist_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actnormの実装\n",
    "class ActNorm2d(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(ActNorm2d, self).__init__()\n",
    "        size = [1, num_features, 1, 1]\n",
    "        self.register_parameter('bias', nn.Parameter(torch.zeros(*size)))\n",
    "        self.register_parameter('log_s', nn.Parameter(torch.zeros(*size)))\n",
    "        self.inited = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.inited:\n",
    "            self.initialize_parameters(x)\n",
    "        \n",
    "        z = torch.exp(self.log_s) * (x + self.bias)\n",
    "        log_det_jacobian = self.calculate_log_det_jacobian(x)\n",
    "        return z, log_det_jacobian\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        x = z * torch.exp(-self.log_s) - self.bias\n",
    "        return x\n",
    "\n",
    "    def calculate_log_det_jacobian(self, x):\n",
    "        h, w = x.size(2), x.size(3)\n",
    "        return h * w * torch.sum(self.log_s)\n",
    "    \n",
    "    def initialize_parameters(self, first_minibatch_x):\n",
    "        with torch.no_grad():\n",
    "            bias = -1.0 * self.multidim_mean(first_minibatch_x.clone(), dims=[0, 2, 3])\n",
    "            var_s = self.multidim_mean((first_minibatch_x.clone() + bias) ** 2, dims=[0, 2, 3])\n",
    "            log_s = torch.log(1 / (torch.sqrt(var_s) + 1e-6))\n",
    "        \n",
    "            self.bias.data.copy_(bias.data)\n",
    "            self.log_s.data.copy_(log_s.data)\n",
    "        \n",
    "            self.inited = True\n",
    "            \n",
    "    def multidim_mean(self, tensor, dims):\n",
    "        dims = sorted(dims)\n",
    "        for d in dims:\n",
    "            tensor = tensor.mean(dim=d, keepdim=True)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invertible 1x1 convolutionの実装\n",
    "class Invertible1x1Conv2d(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Invertible1x1Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(num_features, num_features, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        W = torch.qr(torch.FloatTensor(num_features, num_features).normal_())[0]\n",
    "        \n",
    "        if torch.det(W) < 0:\n",
    "            W[:,0] = -W[:,0]\n",
    "\n",
    "        self.conv.weight.data = W.view(num_features, num_features, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.conv(x)\n",
    "        log_det_jacobian = self.calculate_log_det_jacobian(x)\n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def inverse(self, z, train_finished=False):\n",
    "        if train_finished:\n",
    "            if not hasattr(self, 'W_inverse'):\n",
    "                W = self.conv.weight.squeeze()\n",
    "                W_inverse = W.inverse()\n",
    "                self.W_inverse = W_inverse.view(*W_inverse.size(), 1, 1)\n",
    "            x = F.conv2d(z, self.W_inverse, bias=None, stride=1, padding=0)\n",
    "        else:\n",
    "            W = self.conv.weight.squeeze()\n",
    "            W_inverse = W.inverse().view(*W.size(), 1, 1)\n",
    "            x = F.conv2d(z, W_inverse, bias=None, stride=1, padding=0)\n",
    "        return x\n",
    "        \n",
    "    def calculate_log_det_jacobian(self, x):\n",
    "        W = self.conv.weight.squeeze()\n",
    "        h, w = x.size(2), x.size(3)\n",
    "        return h * w * torch.logdet(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coupling layerで使われるCNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, affine=True):\n",
    "        super(CNN, self).__init__()\n",
    "        self.affine = affine\n",
    "        if affine:\n",
    "            n_out = n_in*2\n",
    "        else:\n",
    "            n_out = n_in\n",
    "            \n",
    "        self.cv1 = nn.Conv2d(n_in, n_hidden, kernel_size=3, stride=1, padding=1)\n",
    "        self.ac1 = ActNorm2d(n_hidden)\n",
    "        self.cv2 = nn.Conv2d(n_hidden, n_hidden, kernel_size=1, stride=1, padding=0)\n",
    "        self.ac2 = ActNorm2d(n_hidden)\n",
    "        self.cv3 = nn.Conv2d(n_hidden, n_out, kernel_size=3, stride=1, padding=1)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, CNN_input):\n",
    "        out = F.relu(self.ac1(self.cv1(CNN_input))[0])\n",
    "        out = F.relu(self.ac2(self.cv2(out))[0])\n",
    "        if self.affine:\n",
    "            out = self.cv3(out)\n",
    "            n_half = int(out.size(1) / 2)\n",
    "            log_s = torch.tanh(out[:,:n_half,:,:])\n",
    "            bias = out[:,n_half:,:,:]\n",
    "            return [log_s, bias]\n",
    "        else:\n",
    "            bias = self.cv3(out)\n",
    "            return bias\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.cv1.weight.data.normal_(0, 0.05)\n",
    "        self.cv1.bias.data.zero_()\n",
    "        self.cv2.weight.data.normal_(0, 0.05)\n",
    "        self.cv2.bias.data.zero_()\n",
    "        self.cv3.weight.data.zero_()\n",
    "        self.cv3.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coupling layerの実装\n",
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, num_features, n_hidden, affine=True):\n",
    "        super(CouplingLayer, self).__init__()\n",
    "        \n",
    "        assert num_features % 2 == 0\n",
    "        self.n_half = int(num_features / 2)\n",
    "        self.affine = affine\n",
    "        \n",
    "        self.CNN = CNN(self.n_half, n_hidden, affine)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x_a = x[:,:self.n_half,:,:]\n",
    "        x_b = x[:,self.n_half:,:,:]\n",
    "        \n",
    "        CNN_output = self.CNN(x_a)\n",
    "        \n",
    "        if self.affine:\n",
    "            log_s = CNN_output[0]\n",
    "            bias = CNN_output[1]\n",
    "            z_b = torch.exp(log_s) * (x_b + bias)\n",
    "        else:\n",
    "            log_s = None\n",
    "            z_b = x_b + CNN_output\n",
    "            \n",
    "        z = torch.cat([x_a, z_b], dim=1)\n",
    "        log_det_jacobian = self.calculate_log_det_jacobian(log_s)\n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def inverse(self, z):\n",
    "        z_a = z[:,:self.n_half,:,:]\n",
    "        z_b = z[:,self.n_half:,:,:]\n",
    "        \n",
    "        CNN_output = self.CNN(z_a)\n",
    "        \n",
    "        if self.affine:\n",
    "            log_s = CNN_output[0]\n",
    "            bias = CNN_output[1]\n",
    "            x_b = z_b * torch.exp(-log_s) - bias\n",
    "        else:\n",
    "            x_b = z_b - CNN_output\n",
    "            \n",
    "        x = torch.cat([z_a, x_b], dim=1)\n",
    "        return x\n",
    "        \n",
    "    def calculate_log_det_jacobian(self, log_s):\n",
    "        if self.affine:\n",
    "            return torch.sum(log_s) / log_s.size(0)\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上３つをまとめたFlow\n",
    "class StepofFlow(nn.Module):\n",
    "    def __init__(self, num_features, n_hidden, affine=True):\n",
    "        super(StepofFlow, self).__init__()\n",
    "        self.actnorm = ActNorm2d(num_features)\n",
    "        self.invertible1x1conv = Invertible1x1Conv2d(num_features)\n",
    "        self.couplinglayer = CouplingLayer(num_features, n_hidden, affine)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, ldj_actnorm  = self.actnorm(x)\n",
    "        # print('after_actnorm', torch.mean(torch.abs(x)))\n",
    "        # print('act', ldj_actnorm)\n",
    "        x, ldj_1x1conv  = self.invertible1x1conv(x)\n",
    "        # print('after_1x1conv', torch.mean(torch.abs(x)))\n",
    "        # print('1x1conv', ldj_1x1conv)\n",
    "        z, ldj_coupling = self.couplinglayer(x)\n",
    "        # print('after_coupling', torch.mean(torch.abs(z)))\n",
    "        # print('coupling', ldj_coupling)\n",
    "        log_det_jacobian = ldj_actnorm + ldj_1x1conv + ldj_coupling\n",
    "        return z, log_det_jacobian\n",
    "    \n",
    "    def inverse(self, z, train_finished=False):\n",
    "        z = self.couplinglayer.inverse(z)\n",
    "        z = self.invertible1x1conv.inverse(z, train_finished)\n",
    "        x = self.actnorm.inverse(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glow本体\n",
    "class Glow(nn.Module):\n",
    "    def __init__(self, L, K, num_input_features, n_hidden_list, affine=True):\n",
    "        super(Glow, self).__init__()\n",
    "        self.L = L\n",
    "        self.K = K\n",
    "        \n",
    "        num_features = num_input_features\n",
    "        assert len(n_hidden_list) == L*K\n",
    "        \n",
    "        self.flow = torch.nn.ModuleList()\n",
    "        for l in range(L):\n",
    "            # squeeze\n",
    "            num_features *= 4\n",
    "            for k in range(K):\n",
    "                # step of flow\n",
    "                self.flow.append(StepofFlow(num_features, int(n_hidden_list[l*K + k]), affine))\n",
    "            # split\n",
    "            num_features = num_features // 2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = []\n",
    "        log_det_jacobian = 0\n",
    "        \n",
    "        for l in range(self.L):\n",
    "            # squeeze\n",
    "            x = self.squeeze(x)\n",
    "            for k in range(self.K):\n",
    "                # step of flow\n",
    "                x, ldj = self.flow[l*self.K + k](x)\n",
    "                log_det_jacobian += ldj\n",
    "            # split\n",
    "            if l == self.L-1:\n",
    "                z.append(x.view(x.size(0), -1))\n",
    "            else:\n",
    "                z.append(x[:,:x.size(1)//2,:,:].view(x.size(0), -1))\n",
    "                x = x[:,x.size(1)//2:,:,:]\n",
    "        \n",
    "        z = torch.cat(z, dim=1)\n",
    "        if not hasattr(self, 'Z'):\n",
    "            batchsize, Z_dim = z.size()\n",
    "            self.Z = MultivariateNormal(torch.zeros(Z_dim).to(device), torch.eye(Z_dim).to(device))\n",
    "            self.last_z_shape = x.size()[1:]\n",
    "            \n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def inverse(self, z, train_finished=False):\n",
    "        x_dim = self.last_z_shape[0] * self.last_z_shape[1] * self.last_z_shape[2]\n",
    "        for l in reversed(range(self.L)):\n",
    "            if l == self.L-1:\n",
    "                x = z[:,-x_dim:].view(-1, *self.last_z_shape)\n",
    "            else:\n",
    "                z_in = z[:,-x_dim*2:-x_dim]\n",
    "                x = torch.cat([z_in.view(*x.size()), x], dim = 1)\n",
    "                x_dim = x_dim*2\n",
    "                \n",
    "            for k in reversed(range(self.K)):\n",
    "                x = self.flow[l*self.K + k].inverse(x, train_finished)\n",
    "                \n",
    "            x = self.unsqueeze(x)\n",
    "        return x\n",
    "                \n",
    "    def squeeze(self, x, factor=2):\n",
    "        batchsize, channels, height, width = x.size()\n",
    "        assert height % factor == 0\n",
    "        assert width % factor == 0\n",
    "        z = x.view(batchsize, channels, height // factor, factor, width // factor, factor)\n",
    "        z = z.permute(0, 1, 3, 5, 2, 4)\n",
    "        z = z.contiguous().view(batchsize, channels * factor**2, height // factor, width // factor)\n",
    "        return z\n",
    "    \n",
    "    def unsqueeze(self, z, factor=2):\n",
    "        batchsize, channels, height, width = z.size()\n",
    "        x = z.view(batchsize, channels // (factor**2), factor, factor, height, width)\n",
    "        x = x.permute(0, 1, 4, 2, 5, 3)\n",
    "        x = x.contiguous().view(batchsize, channels // (factor**2), height * factor, width * factor)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 311104\n"
     ]
    }
   ],
   "source": [
    "net = Glow(L=2, K=16, num_input_features=1, n_hidden_list=np.ones(2*16)*64, affine=True)\n",
    "net = net.to(device)\n",
    "\n",
    "warm_up_epochs = 10\n",
    "learning_rate = 0.001 * (10 ** (-warm_up_epochs))\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "n_epochs = 100\n",
    "save_image_interval = 1\n",
    "n_save_image = 25\n",
    "save_dir = '../../data/glow_MNIST/'\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('The number of parameters:', num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    net.train()\n",
    "    running_loss = 0\n",
    "    for batch_index, sample_x in enumerate(train_loader):\n",
    "        sample_x = sample_x[0].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict_z, log_det_jacobian = net(sample_x)\n",
    "        log_p_z = net.Z.log_prob(predict_z)\n",
    "        log_p_z_mean = torch.mean(log_p_z) / predict_z.size(1)\n",
    "        log_det_jacobian = log_det_jacobian / predict_z.size(1)\n",
    "        loss = -(log_p_z_mean + log_det_jacobian)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        #print('batch_index[%3d/%3d] log_p_z_mean:%1.5f log_det_jacobian:%1.5f' \\\n",
    "        #    % (batch_index+1, len(train_loader), log_p_z_mean.item(), log_det_jacobian.item()))\n",
    "        \n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(validation_loader, epoch):\n",
    "    net.eval()\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sample_x, _ in validation_loader:\n",
    "            sample_x = sample_x.to(device)\n",
    "            \n",
    "            predict_z, log_det_jacobian = net(sample_x)\n",
    "            log_p_z = net.Z.log_prob(predict_z)\n",
    "            log_p_z_mean = torch.mean(log_p_z) / predict_z.size(1)\n",
    "            log_det_jacobian = log_det_jacobian / predict_z.size(1)\n",
    "            loss = -(log_p_z_mean + log_det_jacobian)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if epoch % save_image_interval == 0:\n",
    "            sample_z = net.Z.sample((n_save_image,))\n",
    "            predict_x = net.inverse(sample_z)\n",
    "            print(torch.mean(predict_x))\n",
    "            save_image(predict_x.data.cpu(), '{}/epoch_{}.png'.format(save_dir, epoch), nrow=5, normalize=True)\n",
    "            \n",
    "    return running_loss / len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-24.6744, device='cuda:0')\n",
      "epoch[ 1/100] train_nll:-2.6806 validation_nll:-3.3606\n",
      "tensor(-0.7040, device='cuda:0')\n",
      "epoch[ 2/100] train_nll:-3.4944 validation_nll:-3.0006\n",
      "tensor(-0.8003, device='cuda:0')\n",
      "epoch[ 3/100] train_nll:-3.9324 validation_nll:-4.4616\n",
      "tensor(-0.7677, device='cuda:0')\n",
      "epoch[ 4/100] train_nll:-3.9012 validation_nll:-4.0216\n",
      "tensor(-0.6671, device='cuda:0')\n",
      "epoch[ 5/100] train_nll:-4.4389 validation_nll:-4.9044\n",
      "tensor(-0.7773, device='cuda:0')\n",
      "epoch[ 6/100] train_nll:-4.8315 validation_nll:-5.2430\n",
      "tensor(-0.8243, device='cuda:0')\n",
      "epoch[ 7/100] train_nll:-3.8312 validation_nll:-4.1005\n",
      "tensor(-0.6733, device='cuda:0')\n",
      "epoch[ 8/100] train_nll:-4.4677 validation_nll:-4.6604\n",
      "tensor(-0.7908, device='cuda:0')\n",
      "epoch[ 9/100] train_nll:-4.7320 validation_nll:-4.9848\n",
      "tensor(22.8098, device='cuda:0')\n",
      "epoch[10/100] train_nll:-4.0966 validation_nll:-3.5151\n",
      "tensor(-0.5481, device='cuda:0')\n",
      "epoch[11/100] train_nll:-4.1963 validation_nll:-4.6376\n",
      "tensor(-0.6482, device='cuda:0')\n",
      "epoch[12/100] train_nll:-4.9558 validation_nll:-5.3611\n",
      "tensor(-0.6069, device='cuda:0')\n",
      "epoch[13/100] train_nll:-4.7363 validation_nll:-2.8224\n",
      "tensor(0.5596, device='cuda:0')\n",
      "epoch[14/100] train_nll:-4.7015 validation_nll:-3.7649\n",
      "tensor(-0.7518, device='cuda:0')\n",
      "epoch[15/100] train_nll:-4.5823 validation_nll:-4.0553\n",
      "tensor(-0.7464, device='cuda:0')\n",
      "epoch[16/100] train_nll:-4.6614 validation_nll:-5.0272\n",
      "tensor(-0.7784, device='cuda:0')\n",
      "epoch[17/100] train_nll:-5.2296 validation_nll:-5.5079\n",
      "tensor(-0.7599, device='cuda:0')\n",
      "epoch[18/100] train_nll:-4.6998 validation_nll:-5.2152\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-a18e50333080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_nll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_nll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_validation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-200-09bad5cc36c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpredict_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det_jacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlog_p_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlog_p_z_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p_z\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpredict_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-a55ab547f67b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# step of flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mlog_det_jacobian\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mldj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-197-72c0d779eb23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldj_actnorm\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# print('after_actnorm', torch.mean(torch.abs(x)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# print('act', ldj_actnorm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_buffers'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0m_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_buffers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_nll_list = []\n",
    "validation_nll_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_nll = train(mnist_train_loader)\n",
    "    validation_nll = validation(mnist_validation_loader, epoch)\n",
    "    \n",
    "    train_nll_list.append(train_nll)\n",
    "    validation_nll_list.append(validation_nll)\n",
    "    \n",
    "    if epoch < warm_up_epochs:\n",
    "        optimizer.param_groups[0]['lr'] *= 10\n",
    "    \n",
    "    # print(optimizer.param_groups[0]['lr'])\n",
    "    print('epoch[%2d/%2d] train_nll:%1.4f validation_nll:%1.4f' % (epoch+1, n_epochs, train_nll, validation_nll))\n",
    "\n",
    "torch.save(net.state_dict(), save_dir + 'glow_model.pth')\n",
    "torch.save(optimizer.state_dict(), save_dir + 'glow_optimizer.pth')\n",
    "\n",
    "np.save(save_dir + 'train_nll_list.npy', np.array(train_nll_list))\n",
    "np.save(save_dir + 'validation_nll_list.npy', np.array(validation_nll_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
