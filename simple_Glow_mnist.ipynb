{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.0.0\n",
      "torchvision verseion: 0.2.1\n",
      "Is GPU avaibale: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('torchvision verseion:', torchvision.__version__)\n",
    "print('Is GPU avaibale:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "batchsize = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of training data 60000\n",
      "the number of validation data 10000\n"
     ]
    }
   ],
   "source": [
    "# データセットの準備\n",
    "# Tensorにしつつ、 (-1 ~ 1)の範囲に正規化\n",
    "tf = transforms.Compose([transforms.ToTensor(), \n",
    "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# データセットをロード\n",
    "# 本当はtraining data, validation data, test dataに分けるべきだが、今回は簡便のため2つに分ける.\n",
    "mnist_train = datasets.MNIST(root = '../../data/MNIST',\n",
    "                                 train = True,\n",
    "                                 transform = tf,\n",
    "                                 download = False)\n",
    "mnist_validation = datasets.MNIST(root = '../../data/MNIST',\n",
    "                                      train = False,\n",
    "                                      transform = tf)\n",
    "\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size = batchsize, shuffle = True)\n",
    "mnist_validation_loader = DataLoader(mnist_validation, batch_size = batchsize, shuffle = True)\n",
    "\n",
    "print('the number of training data', len(mnist_train))\n",
    "print('the number of validation data', len(mnist_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62ef55f550>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy() * 0.5 + 0.5\n",
    "    plt.figure(figsize = (5, 5))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "images, labels = iter(mnist_train_loader).next()\n",
    "imshow(make_grid(images[:25], nrow=5, padding=1))\n",
    "print(images[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Invertible1x1Conv(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(Invertible1x1Conv, self).__init__()\n",
    "        \n",
    "    def forward(self, z, reverse=False):\n",
    "        1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, n_in_channels):\n",
    "        super(NN, self).__init__()\n",
    "    def forward(self, forward_input):\n",
    "        1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlowAffineCoupling(nn.Module):\n",
    "    def __init__(self, n_flows, n_group, n_early_every, n_earlysize):\n",
    "        super(Glow, self).__init__()\n",
    "        \n",
    "        assert(n_group % 2 == 0)\n",
    "        self.n_flows = n_flows\n",
    "        self.n_group = n_group\n",
    "        self.n_per_group = None\n",
    "        self.n_early_every = n_early_every\n",
    "        self.n_early_size = n_early_size\n",
    "        \n",
    "        self.NN = torch.nn.ModuleList()\n",
    "        self.convinv = torch.nn.ModuleList()\n",
    "        \n",
    "        n_half = int(n_groups/2)\n",
    "        \n",
    "        n_remaining_channles = n_group\n",
    "        for k in range(n_flows):\n",
    "            if k % self.n_early_every == 0 and k > 0:\n",
    "                n_half = n_half - int(self.n_early_size/2)\n",
    "                n_remaining_channels = n_remaining_channels - self.n_early_size\n",
    "            self.convinv.append(Invertible1x1Conv(n_remaining_channels))\n",
    "            self.NN.append(NN(n_half))\n",
    "        self.n_remaining_channels = n_remaining_channels\n",
    "        \n",
    "    def forward(self, forward_input):\n",
    "        assert(forward_input.size(1) % self.n_group == 0)\n",
    "        self.n_per_group = int(forward_input.size(1) / self.n_group)\n",
    "        \n",
    "        image = forward_input.unfold(1, self.n_group, self.n_group).permute(0, 2, 1)\n",
    "        output_image = []\n",
    "        log_s_list = []\n",
    "        log_det_W_list = []\n",
    "        \n",
    "        for k in range(self.n_flows):\n",
    "            if k % self.n_early_every == 0 and k > 0:\n",
    "                output_image.append(image[:,:self.n_early_size,:])\n",
    "                image = image[:,self.n_early_size:,:]\n",
    "                \n",
    "            image, log_det_W = self.convinv[k](image)\n",
    "            log_det_W_list.append(log_det_W)\n",
    "            \n",
    "            n_half = int(image.size(1)/2)\n",
    "            image_0 = image[:,:n_half,:]\n",
    "            image_1 = image[:,n_half:,:]\n",
    "            \n",
    "            output = self.NN[k](image_0)\n",
    "            log_s = output[:,:n_half,:]\n",
    "            b = output[:,n_half:,:]\n",
    "            image_1 = torch.exp(log_s)*image_1 + b\n",
    "            log_s_list.append(log_s)\n",
    "        \n",
    "            image = torch.cat([image_0, image_1], dim=1)\n",
    "            \n",
    "        output_image.append(image)\n",
    "        return torch.cat(output_image,dim=1), log_s_list, log_det_W_list\n",
    "        \n",
    "    def infer(self, n_sample, simga=1.0):\n",
    "        assert(self.n_per_group == None)\n",
    "        image = torch.cuda.FloatTensor(n_sample, self.n_remaining_channels, n_per_group).normal_()\n",
    "        image = torch.autograd.Variable(sigma*audio)\n",
    "        \n",
    "        for k in reversed(range(self.n_flows)):\n",
    "            n_half = int(image.size(1)/2)\n",
    "            image_0 = image[:,:n_half,:]\n",
    "            image_1 = image[:,n_half:,:]\n",
    "            \n",
    "            output = self.NN[k](image_0)\n",
    "            log_s = output[:,:n_half,:]\n",
    "            b = output[:,:n_half,:]\n",
    "            image_1 = (image_1 - b) / torch.exp(log_s)\n",
    "            \n",
    "            image = torch.cat([image_0, image_1], dim=1)\n",
    "            \n",
    "            image = self.convinv[k](image, reverse=True)\n",
    "            \n",
    "            if k % self.n_early_every == 0 and k > 0:\n",
    "                z = torch.cuda.FloatTensor(n_sample, self.n_early_size, n_per_group).normal_()\n",
    "                image = torch.cat([sigma*z, image], dim=1)\n",
    "        \n",
    "        image = image.permute(0,2,1).contiguous().view(n_sample, -1).data\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0798, -0.8171, -0.9775])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(3).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNVP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RealNVP, self).__init__()\n",
    "        self.affine1 = AffineCouplingLayer()\n",
    "        self.affine2 = AffineCouplingLayer()\n",
    "        self.affine3 = AffineCouplingLayer()\n",
    "        self.affine4 = AffineCouplingLayer()\n",
    "        \n",
    "    def forward(self, z):\n",
    "        x = self.affine1.forward(z)\n",
    "        x = self._reverse(x)\n",
    "        \n",
    "        x = self.affine2.forward(x)\n",
    "        x = self._reverse(x)\n",
    "        \n",
    "        x = self.affine3.forward(x)\n",
    "        x = self._reverse(x)\n",
    "        \n",
    "        x = self.affine4.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def inverse(self, x):\n",
    "        log_det_jacobian = torch.zeros(x.size(0)).to(device)\n",
    "        \n",
    "        z, temp_log_det_jacobian = self.affine4.inverse(x)\n",
    "        log_det_jacobian += temp_log_det_jacobian\n",
    "        z = self._reverse(z)\n",
    "        \n",
    "        z, temp_log_det_jacobian = self.affine3.inverse(z)\n",
    "        log_det_jacobian += temp_log_det_jacobian\n",
    "        z = self._reverse(z)\n",
    "        \n",
    "        z, temp_log_det_jacobian = self.affine2.inverse(z)\n",
    "        log_det_jacobian += temp_log_det_jacobian\n",
    "        z = self._reverse(z)\n",
    "        \n",
    "        z, temp_log_det_jacobian = self.affine1.inverse(z)\n",
    "        log_det_jacobian += temp_log_det_jacobian\n",
    "        \n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def _reverse(self, x):\n",
    "        return x.flip(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 1905568\n"
     ]
    }
   ],
   "source": [
    "net = RealNVP()\n",
    "net = net.to(device)\n",
    "\n",
    "z_dist = MultivariateNormal(torch.zeros(784).to(device), torch.eye(784).to(device))\n",
    "\n",
    "def NLLloss(z, log_det_jacobian):\n",
    "    log_prob = z_dist.log_prob(z) + log_det_jacobian\n",
    "    NLL = -torch.sum(log_prob)\n",
    "    return NLL\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print('The number of parameters:', num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    net.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for inputs, _ in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        \n",
    "        z, log_det_jacobian = net.inverse(inputs)\n",
    "        loss = NLLloss(z, log_det_jacobian)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(validation_loader):\n",
    "    net.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in validation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "  \n",
    "            z, log_det_jacobian = net.inverse(inputs)\n",
    "            loss = NLLloss(z, log_det_jacobian)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        # print('check forward result:', net.forward(torch.randn(10, 784).to(device)))\n",
    "    \n",
    "    validation_loss = running_loss / len(validation_loader.dataset)\n",
    "    \n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/500] train_loss:-814.7871 validation_loss:-829.2823\n",
      "epoch[2/500] train_loss:-829.6317 validation_loss:-833.4712\n",
      "epoch[3/500] train_loss:-832.6807 validation_loss:-835.6683\n",
      "epoch[4/500] train_loss:-834.3527 validation_loss:-836.7827\n",
      "epoch[5/500] train_loss:-835.5266 validation_loss:-837.9955\n",
      "epoch[6/500] train_loss:-836.4589 validation_loss:-838.8218\n",
      "epoch[7/500] train_loss:-837.1834 validation_loss:-839.2993\n",
      "epoch[8/500] train_loss:-837.7729 validation_loss:-839.9189\n",
      "epoch[9/500] train_loss:-838.3070 validation_loss:-840.0844\n",
      "epoch[10/500] train_loss:-838.7306 validation_loss:-840.5647\n",
      "epoch[11/500] train_loss:-839.1132 validation_loss:-840.9130\n",
      "epoch[12/500] train_loss:-839.4614 validation_loss:-841.3059\n",
      "epoch[13/500] train_loss:-839.8022 validation_loss:-841.5016\n",
      "epoch[14/500] train_loss:-840.0757 validation_loss:-841.7832\n",
      "epoch[15/500] train_loss:-840.3209 validation_loss:-841.9219\n",
      "epoch[16/500] train_loss:-840.5519 validation_loss:-842.1529\n",
      "epoch[17/500] train_loss:-840.7666 validation_loss:-842.3264\n",
      "epoch[18/500] train_loss:-840.9710 validation_loss:-842.4227\n",
      "epoch[19/500] train_loss:-841.1667 validation_loss:-842.3095\n",
      "epoch[20/500] train_loss:-841.3140 validation_loss:-842.6295\n",
      "epoch[21/500] train_loss:-841.4752 validation_loss:-842.8466\n",
      "epoch[22/500] train_loss:-841.5959 validation_loss:-842.9785\n",
      "epoch[23/500] train_loss:-841.7207 validation_loss:-843.0247\n",
      "epoch[24/500] train_loss:-841.8380 validation_loss:-843.1575\n",
      "epoch[25/500] train_loss:-841.9462 validation_loss:-843.1471\n",
      "epoch[26/500] train_loss:-842.0748 validation_loss:-843.2793\n",
      "epoch[27/500] train_loss:-842.1522 validation_loss:-843.2597\n",
      "epoch[28/500] train_loss:-842.2559 validation_loss:-843.3158\n",
      "epoch[29/500] train_loss:-842.3492 validation_loss:-843.5333\n",
      "epoch[30/500] train_loss:-842.4269 validation_loss:-843.5331\n",
      "epoch[31/500] train_loss:-842.5093 validation_loss:-843.6413\n",
      "epoch[32/500] train_loss:-842.5810 validation_loss:-843.7344\n",
      "epoch[33/500] train_loss:-842.6496 validation_loss:-843.6251\n",
      "epoch[34/500] train_loss:-842.7238 validation_loss:-843.8001\n",
      "epoch[35/500] train_loss:-842.7933 validation_loss:-843.8239\n",
      "epoch[36/500] train_loss:-842.8403 validation_loss:-843.8589\n",
      "epoch[37/500] train_loss:-842.9086 validation_loss:-843.9379\n",
      "epoch[38/500] train_loss:-842.9629 validation_loss:-843.9842\n",
      "epoch[39/500] train_loss:-843.0359 validation_loss:-844.0168\n",
      "epoch[40/500] train_loss:-843.0823 validation_loss:-844.1270\n",
      "epoch[41/500] train_loss:-843.1182 validation_loss:-844.1104\n",
      "epoch[42/500] train_loss:-843.1769 validation_loss:-844.2123\n",
      "epoch[43/500] train_loss:-843.2159 validation_loss:-844.1742\n",
      "epoch[44/500] train_loss:-843.2708 validation_loss:-844.2481\n",
      "epoch[45/500] train_loss:-843.2944 validation_loss:-844.2267\n",
      "epoch[46/500] train_loss:-843.3602 validation_loss:-844.2813\n",
      "epoch[47/500] train_loss:-843.3899 validation_loss:-844.3395\n",
      "epoch[48/500] train_loss:-843.4452 validation_loss:-844.3876\n",
      "epoch[49/500] train_loss:-843.4805 validation_loss:-844.3569\n",
      "epoch[50/500] train_loss:-843.4944 validation_loss:-844.4207\n",
      "epoch[51/500] train_loss:-843.5368 validation_loss:-844.4827\n",
      "epoch[52/500] train_loss:-843.5873 validation_loss:-844.4246\n",
      "epoch[53/500] train_loss:-843.6041 validation_loss:-844.4402\n",
      "epoch[54/500] train_loss:-843.6514 validation_loss:-844.5830\n",
      "epoch[55/500] train_loss:-843.6857 validation_loss:-844.5659\n",
      "epoch[56/500] train_loss:-843.6993 validation_loss:-844.5479\n",
      "epoch[57/500] train_loss:-843.7549 validation_loss:-844.5523\n",
      "epoch[58/500] train_loss:-843.7873 validation_loss:-844.5856\n",
      "epoch[59/500] train_loss:-843.7952 validation_loss:-844.6345\n",
      "epoch[60/500] train_loss:-843.8283 validation_loss:-844.6228\n",
      "epoch[61/500] train_loss:-843.8752 validation_loss:-844.6546\n",
      "epoch[62/500] train_loss:-843.8737 validation_loss:-844.7067\n",
      "epoch[63/500] train_loss:-843.9103 validation_loss:-844.7493\n",
      "epoch[64/500] train_loss:-843.9352 validation_loss:-844.6521\n",
      "epoch[65/500] train_loss:-843.9606 validation_loss:-844.8029\n",
      "epoch[66/500] train_loss:-844.0004 validation_loss:-844.6985\n",
      "epoch[67/500] train_loss:-844.0050 validation_loss:-844.7415\n",
      "epoch[68/500] train_loss:-844.0377 validation_loss:-844.8318\n",
      "epoch[69/500] train_loss:-844.0626 validation_loss:-844.8396\n",
      "epoch[70/500] train_loss:-844.0615 validation_loss:-844.9475\n",
      "epoch[71/500] train_loss:-844.1098 validation_loss:-844.7196\n",
      "epoch[72/500] train_loss:-844.1222 validation_loss:-844.9186\n",
      "epoch[73/500] train_loss:-844.1551 validation_loss:-844.9308\n",
      "epoch[74/500] train_loss:-844.1647 validation_loss:-844.8740\n",
      "epoch[75/500] train_loss:-844.1876 validation_loss:-844.9745\n",
      "epoch[76/500] train_loss:-844.2034 validation_loss:-844.9556\n",
      "epoch[77/500] train_loss:-844.2354 validation_loss:-844.9009\n",
      "epoch[78/500] train_loss:-844.2460 validation_loss:-845.0723\n",
      "epoch[79/500] train_loss:-844.2629 validation_loss:-845.0123\n",
      "epoch[80/500] train_loss:-844.2779 validation_loss:-845.0036\n",
      "epoch[81/500] train_loss:-844.3112 validation_loss:-845.0182\n",
      "epoch[82/500] train_loss:-844.3214 validation_loss:-845.0849\n",
      "epoch[83/500] train_loss:-844.3436 validation_loss:-845.1421\n",
      "epoch[84/500] train_loss:-844.3749 validation_loss:-845.1243\n",
      "epoch[85/500] train_loss:-844.3669 validation_loss:-845.1233\n",
      "epoch[86/500] train_loss:-844.3970 validation_loss:-845.1323\n",
      "epoch[87/500] train_loss:-844.4155 validation_loss:-845.1398\n",
      "epoch[88/500] train_loss:-844.4253 validation_loss:-845.1048\n",
      "epoch[89/500] train_loss:-844.4304 validation_loss:-845.1329\n",
      "epoch[90/500] train_loss:-844.4565 validation_loss:-845.1956\n",
      "epoch[91/500] train_loss:-844.4740 validation_loss:-845.1471\n",
      "epoch[92/500] train_loss:-844.4946 validation_loss:-845.1270\n",
      "epoch[93/500] train_loss:-844.4693 validation_loss:-845.2375\n",
      "epoch[94/500] train_loss:-844.5011 validation_loss:-845.2271\n",
      "epoch[95/500] train_loss:-844.5301 validation_loss:-845.1936\n",
      "epoch[96/500] train_loss:-844.5421 validation_loss:-844.9044\n",
      "epoch[97/500] train_loss:-844.5453 validation_loss:-845.2960\n",
      "epoch[98/500] train_loss:-844.5736 validation_loss:-845.2199\n",
      "epoch[99/500] train_loss:-844.5832 validation_loss:-845.2157\n",
      "epoch[100/500] train_loss:-844.6033 validation_loss:-845.2213\n",
      "epoch[101/500] train_loss:-844.6042 validation_loss:-845.1861\n",
      "epoch[102/500] train_loss:-844.6166 validation_loss:-845.3262\n",
      "epoch[103/500] train_loss:-844.6323 validation_loss:-845.3536\n",
      "epoch[104/500] train_loss:-844.6449 validation_loss:-845.1706\n",
      "epoch[105/500] train_loss:-844.6677 validation_loss:-845.3053\n",
      "epoch[106/500] train_loss:-844.6819 validation_loss:-845.2934\n",
      "epoch[107/500] train_loss:-844.6887 validation_loss:-845.3308\n",
      "epoch[108/500] train_loss:-844.7056 validation_loss:-845.3305\n",
      "epoch[109/500] train_loss:-844.7132 validation_loss:-845.3083\n",
      "epoch[110/500] train_loss:-844.7219 validation_loss:-845.3897\n",
      "epoch[111/500] train_loss:-844.7315 validation_loss:-845.3204\n",
      "epoch[112/500] train_loss:-844.7361 validation_loss:-845.3465\n",
      "epoch[113/500] train_loss:-844.7544 validation_loss:-845.4219\n",
      "epoch[114/500] train_loss:-844.7632 validation_loss:-845.4141\n",
      "epoch[115/500] train_loss:-844.7661 validation_loss:-845.4581\n",
      "epoch[116/500] train_loss:-844.7504 validation_loss:-845.3670\n",
      "epoch[117/500] train_loss:-844.7983 validation_loss:-845.4313\n",
      "epoch[118/500] train_loss:-844.8122 validation_loss:-845.4431\n",
      "epoch[119/500] train_loss:-844.8134 validation_loss:-845.4018\n",
      "epoch[120/500] train_loss:-844.8239 validation_loss:-845.4582\n",
      "epoch[121/500] train_loss:-844.8159 validation_loss:-845.4113\n",
      "epoch[122/500] train_loss:-844.8364 validation_loss:-845.4922\n",
      "epoch[123/500] train_loss:-844.8649 validation_loss:-845.5047\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "validation_loss_list = []\n",
    "\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(mnist_train_loader)\n",
    "    validation_loss = validation(mnist_validation_loader)\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    validation_loss_list.append(validation_loss)\n",
    "    \n",
    "    print('epoch[%d/%d] train_loss:%1.4f validation_loss:%1.4f' % (epoch+1, n_epochs, train_loss, validation_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[-0.2157, -2.4115,  0.6123, -0.0750,  1.1217, -1.2959, -0.2002, -1.4918,\n",
      "          1.0154,  1.1289,  1.1379, -0.0287,  0.4635,  2.0317, -0.5964, -1.1162,\n",
      "          0.4296, -0.4774,  1.8889, -0.0807,  0.7349, -1.4919,  0.3335, -0.0288,\n",
      "         -0.5386,  1.9902,  1.9387,  1.2725, -1.4224,  1.5829,  0.6326, -0.7735,\n",
      "         -0.2883, -0.9333,  0.7242, -0.2660,  1.0212,  1.1382, -1.9487, -2.3039,\n",
      "          0.4889,  0.8641,  0.1769, -2.3718, -2.8516,  0.0101,  0.9063,  1.4231,\n",
      "         -1.7338, -1.3724,  0.9710, -0.2784,  0.2106,  0.7073, -1.5787, -1.0064,\n",
      "          0.0853,  0.9819,  0.5039,  0.2132,  0.7984,  0.8472, -0.4666,  0.5336,\n",
      "          0.5644,  0.0423,  0.5415,  0.0563, -0.0041, -1.2001,  0.7704, -0.5514,\n",
      "         -0.1776,  0.6190, -0.8204, -0.1107,  0.4295,  0.4872, -0.3170,  1.6208,\n",
      "          1.4675,  1.2417, -0.2540,  0.9322,  1.3290, -0.1684,  1.3501, -0.0211,\n",
      "          0.0395, -0.5071,  0.5957, -0.7861, -0.1754,  0.1548, -0.1348, -0.1903,\n",
      "          2.1890,  0.3060,  0.5581, -0.5896, -2.0370,  0.3053,  0.7464,  0.9452,\n",
      "          0.6028,  1.8109, -2.1419,  0.7498,  1.0886, -0.0898, -0.6424, -0.0401,\n",
      "          1.1593,  0.8320, -1.3569,  0.1603,  0.6181, -1.1018, -1.1936,  1.3969,\n",
      "         -1.7101, -1.6486, -0.6543, -1.4367, -0.2793,  0.7992, -0.6526,  1.7429,\n",
      "          0.1489, -0.6482, -0.7054, -0.1114,  0.0473,  1.5134, -0.2984, -0.3234,\n",
      "          0.7997, -1.2167, -0.6874,  1.5112, -0.2627,  0.9203, -1.0923,  1.4222,\n",
      "         -0.8637, -2.0897,  0.2511,  0.4074, -0.4148,  0.4923,  1.0534, -1.5806,\n",
      "         -1.0446, -0.9757, -0.3808,  1.6126,  0.6192,  0.2222,  1.3879, -0.6808,\n",
      "         -1.0667,  1.7509,  0.7365, -0.0847, -0.4013,  1.2418, -0.5067,  0.2537,\n",
      "         -1.9952, -0.8723, -0.2169,  1.4176, -0.7854, -0.4760,  1.0053, -0.1955,\n",
      "          0.9335,  0.4050,  0.6233, -1.4674, -0.6119,  2.4551, -0.0923, -0.5588,\n",
      "         -0.6227,  0.9575,  0.3456,  0.9624,  0.0434,  0.9783, -0.2110, -0.7729,\n",
      "         -0.9097, -0.4080,  0.7671, -1.0921,  0.0433,  1.2710, -0.2960,  0.1848,\n",
      "          2.0075, -1.0291, -0.0876, -0.2261, -0.4178, -0.1666,  0.7487,  0.3033,\n",
      "          0.6510,  1.5661,  1.5634,  1.7652, -0.5073,  1.8705,  0.0316,  0.4533,\n",
      "          0.0749,  1.2872,  0.2978, -0.4371,  0.6091, -1.3685,  0.9545, -1.1785,\n",
      "          0.2392, -0.4371, -0.4534, -0.0941,  1.0012, -0.5326,  0.6049,  0.9347,\n",
      "          0.4749, -0.5689,  0.3853,  0.3594, -0.0359,  0.8309,  1.0529, -1.0654,\n",
      "          0.3118, -0.6286,  1.3711,  0.9500, -0.9485,  0.9129, -1.4122, -0.1339,\n",
      "         -0.5529,  2.0370, -0.4838, -0.5774,  0.2157,  1.6731, -3.2502,  0.8397,\n",
      "          1.3563,  1.6873,  0.2715,  0.2132,  0.3860, -0.5446, -0.4139, -1.0761,\n",
      "          2.6078,  0.5893,  0.2031, -1.4302, -0.2761,  2.4541,  0.7796,  0.1465,\n",
      "          1.8279, -1.3981, -0.3870,  1.7042,  0.8477, -0.2026, -0.3453,  0.0813,\n",
      "          0.4792, -0.4262, -0.6179,  1.0211,  0.7967, -0.4504,  1.4720,  1.6253,\n",
      "          0.2946, -1.0926, -2.6391, -0.8164, -0.5650,  0.2055,  1.0918, -1.1690,\n",
      "          0.8582,  0.2007,  0.2278, -0.0686, -0.2729, -0.8747,  1.5120, -0.9570,\n",
      "         -0.2118, -1.2201, -0.0282,  0.5360, -1.1564, -0.5159,  0.3059, -0.9945,\n",
      "         -0.7107,  0.8930,  0.5207,  2.6913,  1.4502, -1.2666,  1.1375,  1.2843,\n",
      "         -0.0429,  0.3879, -0.2610, -0.1924,  0.2149,  0.5129,  0.2743, -1.2028,\n",
      "         -0.4059,  0.8287,  0.2068,  0.7910,  0.1504, -0.1554, -0.4651,  0.4678,\n",
      "          0.9368, -0.3464, -1.3809,  1.0833, -2.3197,  0.0387, -1.1746,  1.6415,\n",
      "         -0.7331, -0.4896,  0.0511,  2.5860,  1.1308,  0.2754, -0.1366, -0.0828,\n",
      "         -1.2965, -0.0923, -0.5330,  0.4446, -2.0161,  0.8729,  0.5364,  0.1821,\n",
      "         -0.0910,  1.2174, -0.1930, -1.1044,  1.0994, -0.9474,  1.0715, -0.3321,\n",
      "         -0.6869, -1.6108, -0.7812, -0.7556,  2.4143, -0.1187,  0.5863, -0.4930,\n",
      "          0.0361, -1.3376, -0.5023, -1.6907,  0.6227,  0.6281,  1.9352, -1.3321,\n",
      "          2.0297, -1.6306, -1.8878, -0.6589, -1.2364, -0.4935, -1.3976, -0.2121,\n",
      "          0.3354,  0.4141,  0.1174, -1.2705, -0.1497, -0.9729, -1.0339,  0.6667,\n",
      "         -0.9204, -0.5509,  1.7667,  1.2349,  1.2037,  0.8387, -0.0514,  0.4364,\n",
      "          0.1633,  1.6222, -2.2048, -0.1006, -0.2714,  0.1693,  0.0126,  0.8454,\n",
      "         -0.2328,  0.4172, -2.4026,  2.1026,  0.1637,  0.8929, -0.8458,  0.5454,\n",
      "          0.2200, -0.4075,  0.1123, -0.6181,  0.7142, -1.0318, -0.1310,  1.0793,\n",
      "         -0.1811, -0.8925,  1.8875, -0.3148, -0.0608, -2.5146, -0.6515,  0.7646,\n",
      "         -1.4531, -2.0031,  0.5941,  0.4897,  0.6398,  0.7455,  0.6645, -0.2779,\n",
      "         -0.3177, -1.3756, -0.2556,  0.2383, -0.6277, -0.3878,  1.7083, -1.8719,\n",
      "         -0.6765,  0.0822,  0.9070,  0.4014,  0.5745, -1.0414, -0.0919, -1.6507,\n",
      "         -0.2792, -0.2114,  0.4595,  0.7219, -0.9462,  0.8881, -0.8573,  0.5799,\n",
      "          0.5974,  1.3663,  0.1282,  0.9714, -0.9274,  0.2930,  0.0123, -1.2782,\n",
      "         -0.4007, -0.4324,  0.2546, -0.4493,  0.0376,  0.8437, -0.1750, -0.0573,\n",
      "         -0.2538,  0.2050,  0.7421, -1.0880,  2.4860, -0.2712,  0.4975, -0.5292,\n",
      "         -0.2127,  0.1964,  0.3811,  1.1088, -1.1700,  0.6849,  0.7847, -2.6033,\n",
      "          1.0039,  1.2011, -0.4163, -0.3863, -1.3620,  0.6550,  1.1234,  0.5336,\n",
      "         -0.3905, -0.3071, -2.3845,  1.0659,  1.7717, -0.0731,  1.1431, -0.9779,\n",
      "         -1.1082,  0.2696, -0.4778,  0.9644,  0.1957,  1.5627, -0.3816,  0.8620,\n",
      "          0.4702,  0.6492,  0.5484, -0.0231, -2.0017, -0.8320, -0.3548, -0.2724,\n",
      "         -0.8430,  1.0557, -0.6462, -0.9699,  0.3843, -0.8745,  2.0002,  0.5950,\n",
      "         -0.8538, -0.5119,  1.4866,  0.4716,  0.7741,  0.9307,  0.1338,  0.5752,\n",
      "         -1.6133, -0.0083, -0.2481,  0.0458,  0.1009,  0.0522, -0.5277, -0.4589,\n",
      "         -0.9658,  0.2566, -1.1543, -1.2493,  0.6978,  0.2591,  0.6825,  1.4614,\n",
      "         -1.4769, -1.5026,  2.1583, -1.8726, -0.6644, -0.2441,  2.4222,  0.0869,\n",
      "         -1.0498, -1.6520,  1.3422, -1.0376, -0.8912,  0.7265,  0.1533, -0.7275,\n",
      "         -0.3747,  0.6592, -1.4341, -0.0412,  0.6061, -1.1652,  0.9880, -1.8116,\n",
      "         -0.0112,  0.3224, -1.3097, -0.4732, -0.0247,  0.6599,  0.7679, -0.1867,\n",
      "          0.2138,  2.0379, -1.6053, -0.4840, -2.1592, -0.8907, -0.4195,  1.1744,\n",
      "         -0.7782, -0.2283,  0.3276,  1.0598, -1.1347,  0.6062, -0.7955, -0.6464,\n",
      "         -1.7465, -0.5239,  0.4018,  1.4059,  0.7822, -0.7406,  0.8461, -3.2856,\n",
      "         -1.8630,  1.1360, -2.3442, -1.5018, -0.7620,  0.4878,  0.0466, -1.3222,\n",
      "          0.8515, -0.4293, -0.5095,  0.4690,  0.9963,  1.0354, -0.4253, -1.1671,\n",
      "          1.1542, -1.2211,  1.9337, -1.0556, -1.2893, -0.5149,  0.4087,  0.7020,\n",
      "          0.9203, -0.3114,  0.7942,  0.9089,  0.4404,  1.7279, -0.9469, -0.2209,\n",
      "          1.2453,  0.3174,  0.5410,  0.4373,  1.6329,  0.7696,  0.1667,  1.1442,\n",
      "         -2.4613, -1.1779,  0.5655,  1.3024, -0.7797,  0.9577,  1.0991, -1.5095,\n",
      "         -2.0463,  2.2063, -0.0148,  0.2244,  1.2066, -0.6449, -1.1527, -1.6193,\n",
      "         -2.6122,  0.2262, -0.2229, -1.2668,  1.2170,  0.5302, -0.3565, -0.0681,\n",
      "         -0.8455, -0.1072, -0.4771, -0.1824,  0.7253,  1.2986,  0.1041, -0.6736,\n",
      "          1.4014, -0.1301,  0.0711, -0.9890, -0.3835,  0.1828, -0.3266, -0.0121,\n",
      "         -1.3065,  0.0526,  0.7447,  1.8386,  0.8011,  0.1670, -0.4123,  0.0903,\n",
      "          0.0567,  0.0266, -0.1253, -1.9124,  0.8092, -1.0814, -2.6339, -0.6369,\n",
      "          1.6992, -0.7298, -0.3592, -0.2758, -1.5436,  1.0447,  1.0972,  2.4359,\n",
      "          0.6864,  0.2768, -0.2187,  1.6110, -0.2457,  0.6533,  0.6105,  0.2107,\n",
      "          1.5318,  1.6211,  0.5222,  0.2862, -0.2917, -0.2354, -1.0354,  0.2708,\n",
      "         -0.3996, -0.6033,  1.0904,  0.0228, -0.7559, -2.0354,  0.5750, -0.2759,\n",
      "          1.7988, -0.1202,  1.8114, -1.2093,  0.6628, -0.0939, -0.4272, -0.6860,\n",
      "         -0.6367,  0.4708, -0.5383, -1.0373,  0.0570, -0.6942,  0.6973, -0.3605,\n",
      "         -0.0556,  0.1904,  0.7037,  1.1490,  0.2813, -1.8179, -0.5975, -2.7680,\n",
      "         -1.1045,  2.0679, -0.9015, -0.8996, -0.2093,  0.0914,  0.2985, -2.1319]],\n",
      "       device='cuda:0')\n",
      "y tensor([[-0.2157, -2.4115,  0.6123, -0.0750,  1.1217, -1.2959, -0.2002, -1.4918,\n",
      "          1.0154,  1.1289,  1.1379, -0.0287,  0.4635,  2.0317, -0.5964, -1.1162,\n",
      "          0.4296, -0.4774,  1.8889, -0.0807,  0.7349, -1.4919,  0.3335, -0.0288,\n",
      "         -0.5386,  1.9902,  1.9387,  1.2725, -1.4224,  1.5829,  0.6326, -0.7735,\n",
      "         -0.2883, -0.9333,  0.7242, -0.2660,  1.0212,  1.1382, -1.9487, -2.3039,\n",
      "          0.4889,  0.8641,  0.1769, -2.3718, -2.8516,  0.0101,  0.9063,  1.4231,\n",
      "         -1.7338, -1.3724,  0.9710, -0.2784,  0.2106,  0.7073, -1.5787, -1.0064,\n",
      "          0.0853,  0.9819,  0.5039,  0.2132,  0.7984,  0.8472, -0.4666,  0.5336,\n",
      "          0.5644,  0.0423,  0.5415,  0.0563, -0.0041, -1.2001,  0.7704, -0.5514,\n",
      "         -0.1776,  0.6190, -0.8204, -0.1107,  0.4295,  0.4872, -0.3170,  1.6208,\n",
      "          1.4675,  1.2417, -0.2540,  0.9322,  1.3290, -0.1684,  1.3501, -0.0211,\n",
      "          0.0395, -0.5071,  0.5957, -0.7861, -0.1754,  0.1548, -0.1348, -0.1903,\n",
      "          2.1890,  0.3060,  0.5581, -0.5896, -2.0370,  0.3053,  0.7464,  0.9452,\n",
      "          0.6028,  1.8109, -2.1419,  0.7498,  1.0886, -0.0898, -0.6424, -0.0401,\n",
      "          1.1593,  0.8320, -1.3569,  0.1603,  0.6181, -1.1018, -1.1936,  1.3969,\n",
      "         -1.7101, -1.6486, -0.6543, -1.4367, -0.2793,  0.7992, -0.6526,  1.7429,\n",
      "          0.1489, -0.6482, -0.7054, -0.1114,  0.0473,  1.5134, -0.2984, -0.3234,\n",
      "          0.7997, -1.2167, -0.6874,  1.5112, -0.2627,  0.9203, -1.0923,  1.4222,\n",
      "         -0.8637, -2.0897,  0.2511,  0.4074, -0.4148,  0.4923,  1.0534, -1.5806,\n",
      "         -1.0446, -0.9757, -0.3808,  1.6126,  0.6192,  0.2222,  1.3879, -0.6808,\n",
      "         -1.0667,  1.7509,  0.7365, -0.0847, -0.4013,  1.2418, -0.5067,  0.2537,\n",
      "         -1.9952, -0.8723, -0.2169,  1.4176, -0.7854, -0.4760,  1.0053, -0.1955,\n",
      "          0.9335,  0.4050,  0.6233, -1.4674, -0.6119,  2.4551, -0.0923, -0.5588,\n",
      "         -0.6227,  0.9575,  0.3456,  0.9624,  0.0434,  0.9783, -0.2110, -0.7729,\n",
      "         -0.9097, -0.4080,  0.7671, -1.0921,  0.0433,  1.2710, -0.2960,  0.1848,\n",
      "          2.0075, -1.0291, -0.0876, -0.2261, -0.4178, -0.1666,  0.7487,  0.3033,\n",
      "          0.6510,  1.5661,  1.5634,  1.7652, -0.5073,  1.8705,  0.0316,  0.4533,\n",
      "          0.0749,  1.2872,  0.2978, -0.4371,  0.6091, -1.3685,  0.9545, -1.1785,\n",
      "          0.2392, -0.4371, -0.4534, -0.0941,  1.0012, -0.5326,  0.6049,  0.9347,\n",
      "          0.4749, -0.5689,  0.3853,  0.3594, -0.0359,  0.8309,  1.0529, -1.0654,\n",
      "          0.3118, -0.6286,  1.3711,  0.9500, -0.9485,  0.9129, -1.4122, -0.1339,\n",
      "         -0.5529,  2.0370, -0.4838, -0.5774,  0.2157,  1.6731, -3.2502,  0.8397,\n",
      "          1.3563,  1.6873,  0.2715,  0.2132,  0.3860, -0.5446, -0.4139, -1.0761,\n",
      "          2.6078,  0.5893,  0.2031, -1.4302, -0.2761,  2.4541,  0.7796,  0.1465,\n",
      "          1.8279, -1.3981, -0.3870,  1.7042,  0.8477, -0.2026, -0.3453,  0.0813,\n",
      "          0.4792, -0.4262, -0.6179,  1.0211,  0.7967, -0.4504,  1.4720,  1.6253,\n",
      "          0.2946, -1.0926, -2.6391, -0.8164, -0.5650,  0.2055,  1.0918, -1.1690,\n",
      "          0.8582,  0.2007,  0.2278, -0.0686, -0.2729, -0.8747,  1.5120, -0.9570,\n",
      "         -0.2118, -1.2201, -0.0282,  0.5360, -1.1564, -0.5159,  0.3059, -0.9945,\n",
      "         -0.7107,  0.8930,  0.5207,  2.6913,  1.4502, -1.2666,  1.1375,  1.2843,\n",
      "         -0.0429,  0.3879, -0.2610, -0.1924,  0.2149,  0.5129,  0.2743, -1.2028,\n",
      "         -0.4059,  0.8287,  0.2068,  0.7910,  0.1504, -0.1554, -0.4651,  0.4678,\n",
      "          0.9368, -0.3464, -1.3809,  1.0833, -2.3197,  0.0387, -1.1746,  1.6415,\n",
      "         -0.7331, -0.4896,  0.0511,  2.5860,  1.1308,  0.2754, -0.1366, -0.0828,\n",
      "         -1.2965, -0.0923, -0.5330,  0.4446, -2.0161,  0.8729,  0.5364,  0.1821,\n",
      "         -0.0910,  1.2174, -0.1930, -1.1044,  1.0994, -0.9474,  1.0715, -0.3321,\n",
      "         -0.6869, -1.6108, -0.7812, -0.7556,  2.4143, -0.1187,  0.5863, -0.4930,\n",
      "          0.0361, -1.3376, -0.5023, -1.6907,  0.6227,  0.6281,  1.9352, -1.3321,\n",
      "          2.0297, -1.6306, -1.8878, -0.6589, -1.2364, -0.4935, -1.3976, -0.2121,\n",
      "          0.3172,  0.3834,  0.1404, -1.2306, -0.1149, -0.9852, -1.0321,  0.6598,\n",
      "         -0.8878, -0.5600,  1.8091,  1.2900,  1.1618,  0.8470, -0.0653,  0.4283,\n",
      "          0.0966,  1.6117, -2.1294, -0.0911, -0.2907,  0.2187,  0.0249,  0.9321,\n",
      "         -0.2655,  0.4744, -2.3379,  2.1810,  0.1574,  0.8923, -0.8900,  0.5672,\n",
      "          0.1921, -0.5090,  0.0822, -0.5652,  0.7043, -1.0334, -0.1156,  1.1667,\n",
      "         -0.1224, -0.9051,  1.9402, -0.2121, -0.1229, -2.4088, -0.6636,  0.8558,\n",
      "         -1.4229, -1.9731,  0.5831,  0.4542,  0.7119,  0.7449,  0.6226, -0.2692,\n",
      "         -0.3762, -1.3703, -0.2875,  0.2142, -0.7012, -0.4251,  1.5451, -1.9428,\n",
      "         -0.7090,  0.1513,  0.9700,  0.4354,  0.6279, -0.9611, -0.1574, -1.7601,\n",
      "         -0.2628, -0.1704,  0.4237,  0.7917, -0.8607,  0.9310, -0.8920,  0.6133,\n",
      "          0.5800,  1.3641,  0.1841,  0.9234, -0.9070,  0.3264,  0.0036, -1.3927,\n",
      "         -0.3557, -0.4105,  0.2724, -0.4812,  0.0169,  0.8144, -0.2205, -0.0581,\n",
      "         -0.1912,  0.2175,  0.7906, -1.0832,  2.4474, -0.3167,  0.5104, -0.5357,\n",
      "         -0.2035,  0.1572,  0.4333,  1.0706, -1.1632,  0.6228,  0.7234, -2.5083,\n",
      "          1.1234,  1.2034, -0.3741, -0.4531, -1.2815,  0.6625,  1.1269,  0.4923,\n",
      "         -0.3804, -0.2759, -2.2033,  1.0612,  1.8774, -0.0974,  1.1037, -1.1066,\n",
      "         -1.1413,  0.1792, -0.4382,  0.9777,  0.2259,  1.6261, -0.3458,  0.8875,\n",
      "          0.4674,  0.6501,  0.5021, -0.0255, -2.0048, -0.9147, -0.3720, -0.3036,\n",
      "         -0.7918,  1.0070, -0.6298, -0.9919,  0.3563, -0.9577,  1.8972,  0.6483,\n",
      "         -0.8352, -0.4989,  1.3152,  0.4070,  0.8286,  1.0145,  0.1757,  0.5573,\n",
      "         -1.6119,  0.0191, -0.2250,  0.0214,  0.0610,  0.0513, -0.4567, -0.5449,\n",
      "         -0.8882,  0.2688, -1.1345, -1.1815,  0.6241,  0.2613,  0.7160,  1.5449,\n",
      "         -1.4928, -1.5699,  2.2112, -1.8423, -0.6461, -0.2988,  2.4130,  0.1279,\n",
      "         -0.9400, -1.8204,  1.4376, -1.1280, -0.8307,  0.7560,  0.1252, -0.7383,\n",
      "         -0.3848,  0.5921, -1.4179, -0.1013,  0.6994, -1.2197,  0.9513, -1.8079,\n",
      "         -0.0954,  0.3667, -1.3643, -0.5619,  0.0071,  0.6509,  0.8181, -0.2057,\n",
      "          0.1851,  2.2241, -1.5887, -0.4400, -2.3225, -0.8488, -0.4724,  1.1998,\n",
      "         -0.9395, -0.2375,  0.3445,  1.0359, -1.1689,  0.6519, -0.7703, -0.7156,\n",
      "         -1.7945, -0.5562,  0.3875,  1.4565,  0.7737, -0.6874,  0.8449, -3.3822,\n",
      "         -1.9249,  1.1504, -2.4346, -1.6380, -0.6405,  0.4569,  0.0321, -1.3091,\n",
      "          0.8798, -0.4580, -0.4437,  0.4595,  1.0405,  0.9682, -0.4190, -1.2402,\n",
      "          1.1074, -1.1190,  1.8772, -1.0985, -1.1881, -0.4681,  0.3766,  0.6651,\n",
      "          0.8501, -0.2691,  0.7761,  0.9441,  0.4740,  1.6746, -0.9148, -0.2545,\n",
      "          1.2996,  0.3400,  0.5687,  0.4200,  1.7453,  0.8338,  0.1579,  1.0184,\n",
      "         -2.5834, -1.1517,  0.6409,  1.3478, -0.7985,  0.8594,  1.1352, -1.5245,\n",
      "         -2.1239,  2.0533, -0.0073,  0.1924,  1.2724, -0.6596, -1.1874, -1.5544,\n",
      "         -2.6664,  0.1381, -0.1761, -1.1694,  1.1908,  0.5947, -0.3165, -0.0357,\n",
      "         -0.7929, -0.1321, -0.4034, -0.1490,  0.6683,  1.2615,  0.1032, -0.6891,\n",
      "          1.3105, -0.1500,  0.0728, -1.0258, -0.3877,  0.1759, -0.4285,  0.0166,\n",
      "         -1.1655,  0.0069,  0.7777,  1.7642,  0.7348,  0.1870, -0.4333,  0.0844,\n",
      "          0.0906,  0.0462, -0.1970, -1.8379,  0.8128, -1.0843, -2.5885, -0.7533,\n",
      "          1.5701, -0.6973, -0.3857, -0.2700, -1.6795,  1.0936,  1.0811,  2.4245,\n",
      "          0.7474,  0.2615, -0.2119,  1.7163, -0.3497,  0.6425,  0.5940,  0.2345,\n",
      "          1.6248,  1.7075,  0.5232,  0.2288, -0.2886, -0.2070, -1.0579,  0.1564,\n",
      "         -0.3857, -0.6663,  1.0760,  0.0895, -0.8622, -2.0383,  0.6050, -0.2709,\n",
      "          1.8780, -0.0322,  1.8578, -1.2885,  0.7243, -0.0792, -0.4943, -0.6851,\n",
      "         -0.6254,  0.3823, -0.4863, -1.1269,  0.0117, -0.6853,  0.7798, -0.4127,\n",
      "         -0.0733,  0.1750,  0.6377,  1.2084,  0.2955, -1.8159, -0.5826, -2.6576,\n",
      "         -1.1649,  1.8860, -0.9484, -0.9269, -0.2257,  0.1683,  0.2927, -2.0968]],\n",
      "       device='cuda:0')\n",
      "x tensor([[-2.0968,  0.2927,  0.1683, -0.2257, -0.9269, -0.9484,  1.8860, -1.1649,\n",
      "         -2.6576, -0.5826, -1.8159,  0.2955,  1.2084,  0.6377,  0.1750, -0.0733,\n",
      "         -0.4127,  0.7798, -0.6853,  0.0117, -1.1269, -0.4863,  0.3823, -0.6254,\n",
      "         -0.6851, -0.4943, -0.0792,  0.7243, -1.2885,  1.8578, -0.0322,  1.8780,\n",
      "         -0.2709,  0.6050, -2.0383, -0.8622,  0.0895,  1.0760, -0.6663, -0.3857,\n",
      "          0.1564, -1.0579, -0.2070, -0.2886,  0.2288,  0.5232,  1.7075,  1.6248,\n",
      "          0.2345,  0.5940,  0.6425, -0.3497,  1.7163, -0.2119,  0.2615,  0.7474,\n",
      "          2.4245,  1.0811,  1.0936, -1.6795, -0.2700, -0.3857, -0.6973,  1.5701,\n",
      "         -0.7533, -2.5885, -1.0843,  0.8128, -1.8379, -0.1970,  0.0462,  0.0906,\n",
      "          0.0844, -0.4333,  0.1870,  0.7348,  1.7642,  0.7777,  0.0069, -1.1655,\n",
      "          0.0166, -0.4285,  0.1759, -0.3877, -1.0258,  0.0728, -0.1500,  1.3105,\n",
      "         -0.6891,  0.1032,  1.2615,  0.6683, -0.1490, -0.4034, -0.1321, -0.7929,\n",
      "         -0.0357, -0.3165,  0.5947,  1.1908, -1.1694, -0.1761,  0.1381, -2.6664,\n",
      "         -1.5544, -1.1874, -0.6596,  1.2724,  0.1924, -0.0073,  2.0533, -2.1239,\n",
      "         -1.5245,  1.1352,  0.8594, -0.7985,  1.3478,  0.6409, -1.1517, -2.5834,\n",
      "          1.0184,  0.1579,  0.8338,  1.7453,  0.4200,  0.5687,  0.3400,  1.2996,\n",
      "         -0.2545, -0.9148,  1.6746,  0.4740,  0.9441,  0.7761, -0.2691,  0.8501,\n",
      "          0.6651,  0.3766, -0.4681, -1.1881, -1.0985,  1.8772, -1.1190,  1.1074,\n",
      "         -1.2402, -0.4190,  0.9682,  1.0405,  0.4595, -0.4437, -0.4580,  0.8798,\n",
      "         -1.3091,  0.0321,  0.4569, -0.6405, -1.6380, -2.4346,  1.1504, -1.9249,\n",
      "         -3.3822,  0.8449, -0.6874,  0.7737,  1.4565,  0.3875, -0.5562, -1.7945,\n",
      "         -0.7156, -0.7703,  0.6519, -1.1689,  1.0359,  0.3445, -0.2375, -0.9395,\n",
      "          1.1998, -0.4724, -0.8488, -2.3225, -0.4400, -1.5887,  2.2241,  0.1851,\n",
      "         -0.2057,  0.8181,  0.6509,  0.0071, -0.5619, -1.3643,  0.3667, -0.0954,\n",
      "         -1.8079,  0.9513, -1.2197,  0.6994, -0.1013, -1.4179,  0.5921, -0.3848,\n",
      "         -0.7383,  0.1252,  0.7560, -0.8307, -1.1280,  1.4376, -1.8204, -0.9400,\n",
      "          0.1279,  2.4130, -0.2988, -0.6461, -1.8423,  2.2112, -1.5699, -1.4928,\n",
      "          1.5449,  0.7160,  0.2613,  0.6241, -1.1815, -1.1345,  0.2688, -0.8882,\n",
      "         -0.5449, -0.4567,  0.0513,  0.0610,  0.0214, -0.2250,  0.0191, -1.6119,\n",
      "          0.5573,  0.1757,  1.0145,  0.8286,  0.4070,  1.3152, -0.4989, -0.8352,\n",
      "          0.6483,  1.8972, -0.9577,  0.3563, -0.9919, -0.6298,  1.0070, -0.7918,\n",
      "         -0.3036, -0.3720, -0.9147, -2.0048, -0.0255,  0.5021,  0.6501,  0.4674,\n",
      "          0.8875, -0.3458,  1.6261,  0.2259,  0.9777, -0.4382,  0.1792, -1.1413,\n",
      "         -1.1066,  1.1037, -0.0974,  1.8774,  1.0612, -2.2033, -0.2759, -0.3804,\n",
      "          0.4923,  1.1269,  0.6625, -1.2815, -0.4531, -0.3741,  1.2034,  1.1234,\n",
      "         -2.5083,  0.7234,  0.6228, -1.1632,  1.0706,  0.4333,  0.1572, -0.2035,\n",
      "         -0.5357,  0.5104, -0.3167,  2.4474, -1.0832,  0.7906,  0.2175, -0.1912,\n",
      "         -0.0581, -0.2205,  0.8144,  0.0169, -0.4812,  0.2724, -0.4105, -0.3557,\n",
      "         -1.3927,  0.0036,  0.3264, -0.9070,  0.9234,  0.1841,  1.3641,  0.5800,\n",
      "          0.6133, -0.8920,  0.9310, -0.8607,  0.7917,  0.4237, -0.1704, -0.2628,\n",
      "         -1.7601, -0.1574, -0.9611,  0.6279,  0.4354,  0.9700,  0.1513, -0.7090,\n",
      "         -1.9428,  1.5451, -0.4251, -0.7012,  0.2142, -0.2875, -1.3703, -0.3762,\n",
      "         -0.2692,  0.6226,  0.7449,  0.7119,  0.4542,  0.5831, -1.9731, -1.4229,\n",
      "          0.8558, -0.6636, -2.4088, -0.1229, -0.2121,  1.9402, -0.9051, -0.1224,\n",
      "          1.1667, -0.1156, -1.0334,  0.7043, -0.5652,  0.0822, -0.5090,  0.1921,\n",
      "          0.5672, -0.8900,  0.8923,  0.1574,  2.1810, -2.3379,  0.4744, -0.2655,\n",
      "          0.9321,  0.0249,  0.2187, -0.2907, -0.0911, -2.1294,  1.6117,  0.0966,\n",
      "          0.4283, -0.0653,  0.8470,  1.1618,  1.2900,  1.8091, -0.5600, -0.8878,\n",
      "          0.6598, -1.0321, -0.9852, -0.1149, -1.2306,  0.1404,  0.3834,  0.3172,\n",
      "         -0.2121, -1.3976, -0.4935, -1.2364, -0.6589, -1.8878, -1.6306,  2.0297,\n",
      "         -1.3321,  1.9352,  0.6281,  0.6227, -1.6907, -0.5023, -1.3376,  0.0361,\n",
      "         -0.4930,  0.5863, -0.1187,  2.4143, -0.7556, -0.7812, -1.6108, -0.6869,\n",
      "         -0.3321,  1.0715, -0.9474,  1.0994, -1.1044, -0.1930,  1.2174, -0.0910,\n",
      "          0.1821,  0.5364,  0.8729, -2.0161,  0.4446, -0.5330, -0.0923, -1.2965,\n",
      "         -0.0828, -0.1366,  0.2754,  1.1308,  2.5860,  0.0511, -0.4896, -0.7331,\n",
      "          1.6415, -1.1746,  0.0387, -2.3197,  1.0833, -1.3809, -0.3464,  0.9368,\n",
      "          0.4678, -0.4651, -0.1554,  0.1504,  0.7910,  0.2068,  0.8287, -0.4059,\n",
      "         -1.2028,  0.2743,  0.5129,  0.2149, -0.1924, -0.2610,  0.3879, -0.0429,\n",
      "          1.2843,  1.1375, -1.2666,  1.4502,  2.6913,  0.5207,  0.8930, -0.7107,\n",
      "         -0.9945,  0.3059, -0.5159, -1.1564,  0.5360, -0.0282, -1.2201, -0.2118,\n",
      "         -0.9570,  1.5120, -0.8747, -0.2729, -0.0686,  0.2278,  0.2007,  0.8582,\n",
      "         -1.1690,  1.0918,  0.2055, -0.5650, -0.8164, -2.6391, -1.0926,  0.2946,\n",
      "          1.6253,  1.4720, -0.4504,  0.7967,  1.0211, -0.6179, -0.4262,  0.4792,\n",
      "          0.0813, -0.3453, -0.2026,  0.8477,  1.7042, -0.3870, -1.3981,  1.8279,\n",
      "          0.1465,  0.7796,  2.4541, -0.2761, -1.4302,  0.2031,  0.5893,  2.6078,\n",
      "         -1.0761, -0.4139, -0.5446,  0.3860,  0.2132,  0.2715,  1.6873,  1.3563,\n",
      "          0.8397, -3.2502,  1.6731,  0.2157, -0.5774, -0.4838,  2.0370, -0.5529,\n",
      "         -0.1339, -1.4122,  0.9129, -0.9485,  0.9500,  1.3711, -0.6286,  0.3118,\n",
      "         -1.0654,  1.0529,  0.8309, -0.0359,  0.3594,  0.3853, -0.5689,  0.4749,\n",
      "          0.9347,  0.6049, -0.5326,  1.0012, -0.0941, -0.4534, -0.4371,  0.2392,\n",
      "         -1.1785,  0.9545, -1.3685,  0.6091, -0.4371,  0.2978,  1.2872,  0.0749,\n",
      "          0.4533,  0.0316,  1.8705, -0.5073,  1.7652,  1.5634,  1.5661,  0.6510,\n",
      "          0.3033,  0.7487, -0.1666, -0.4178, -0.2261, -0.0876, -1.0291,  2.0075,\n",
      "          0.1848, -0.2960,  1.2710,  0.0433, -1.0921,  0.7671, -0.4080, -0.9097,\n",
      "         -0.7729, -0.2110,  0.9783,  0.0434,  0.9624,  0.3456,  0.9575, -0.6227,\n",
      "         -0.5588, -0.0923,  2.4551, -0.6119, -1.4674,  0.6233,  0.4050,  0.9335,\n",
      "         -0.1955,  1.0053, -0.4760, -0.7854,  1.4176, -0.2169, -0.8723, -1.9952,\n",
      "          0.2537, -0.5067,  1.2418, -0.4013, -0.0847,  0.7365,  1.7509, -1.0667,\n",
      "         -0.6808,  1.3879,  0.2222,  0.6192,  1.6126, -0.3808, -0.9757, -1.0446,\n",
      "         -1.5806,  1.0534,  0.4923, -0.4148,  0.4074,  0.2511, -2.0897, -0.8637,\n",
      "          1.4222, -1.0923,  0.9203, -0.2627,  1.5112, -0.6874, -1.2167,  0.7997,\n",
      "         -0.3234, -0.2984,  1.5134,  0.0473, -0.1114, -0.7054, -0.6482,  0.1489,\n",
      "          1.7429, -0.6526,  0.7992, -0.2793, -1.4367, -0.6543, -1.6486, -1.7101,\n",
      "          1.3969, -1.1936, -1.1018,  0.6181,  0.1603, -1.3569,  0.8320,  1.1593,\n",
      "         -0.0401, -0.6424, -0.0898,  1.0886,  0.7498, -2.1419,  1.8109,  0.6028,\n",
      "          0.9452,  0.7464,  0.3053, -2.0370, -0.5896,  0.5581,  0.3060,  2.1890,\n",
      "         -0.1903, -0.1348,  0.1548, -0.1754, -0.7861,  0.5957, -0.5071,  0.0395,\n",
      "         -0.0211,  1.3501, -0.1684,  1.3290,  0.9322, -0.2540,  1.2417,  1.4675,\n",
      "          1.6208, -0.3170,  0.4872,  0.4295, -0.1107, -0.8204,  0.6190, -0.1776,\n",
      "         -0.5514,  0.7704, -1.2001, -0.0041,  0.0563,  0.5415,  0.0423,  0.5644,\n",
      "          0.5336, -0.4666,  0.8472,  0.7984,  0.2132,  0.5039,  0.9819,  0.0853,\n",
      "         -1.0064, -1.5787,  0.7073,  0.2106, -0.2784,  0.9710, -1.3724, -1.7338,\n",
      "          1.4231,  0.9063,  0.0101, -2.8516, -2.3718,  0.1769,  0.8641,  0.4889,\n",
      "         -2.3039, -1.9487,  1.1382,  1.0212, -0.2660,  0.7242, -0.9333, -0.2883,\n",
      "         -0.7735,  0.6326,  1.5829, -1.4224,  1.2725,  1.9387,  1.9902, -0.5386,\n",
      "         -0.0288,  0.3335, -1.4919,  0.7349, -0.0807,  1.8889, -0.4774,  0.4296,\n",
      "         -1.1162, -0.5964,  2.0317,  0.4635, -0.0287,  1.1379,  1.1289,  1.0154,\n",
      "         -1.4918, -0.2002, -1.2959,  1.1217, -0.0750,  0.6123, -2.4115, -0.2157]],\n",
      "       device='cuda:0')\n",
      "y tensor([[-2.0968,  0.2927,  0.1683, -0.2257, -0.9269, -0.9484,  1.8860, -1.1649,\n",
      "         -2.6576, -0.5826, -1.8159,  0.2955,  1.2084,  0.6377,  0.1750, -0.0733,\n",
      "         -0.4127,  0.7798, -0.6853,  0.0117, -1.1269, -0.4863,  0.3823, -0.6254,\n",
      "         -0.6851, -0.4943, -0.0792,  0.7243, -1.2885,  1.8578, -0.0322,  1.8780,\n",
      "         -0.2709,  0.6050, -2.0383, -0.8622,  0.0895,  1.0760, -0.6663, -0.3857,\n",
      "          0.1564, -1.0579, -0.2070, -0.2886,  0.2288,  0.5232,  1.7075,  1.6248,\n",
      "          0.2345,  0.5940,  0.6425, -0.3497,  1.7163, -0.2119,  0.2615,  0.7474,\n",
      "          2.4245,  1.0811,  1.0936, -1.6795, -0.2700, -0.3857, -0.6973,  1.5701,\n",
      "         -0.7533, -2.5885, -1.0843,  0.8128, -1.8379, -0.1970,  0.0462,  0.0906,\n",
      "          0.0844, -0.4333,  0.1870,  0.7348,  1.7642,  0.7777,  0.0069, -1.1655,\n",
      "          0.0166, -0.4285,  0.1759, -0.3877, -1.0258,  0.0728, -0.1500,  1.3105,\n",
      "         -0.6891,  0.1032,  1.2615,  0.6683, -0.1490, -0.4034, -0.1321, -0.7929,\n",
      "         -0.0357, -0.3165,  0.5947,  1.1908, -1.1694, -0.1761,  0.1381, -2.6664,\n",
      "         -1.5544, -1.1874, -0.6596,  1.2724,  0.1924, -0.0073,  2.0533, -2.1239,\n",
      "         -1.5245,  1.1352,  0.8594, -0.7985,  1.3478,  0.6409, -1.1517, -2.5834,\n",
      "          1.0184,  0.1579,  0.8338,  1.7453,  0.4200,  0.5687,  0.3400,  1.2996,\n",
      "         -0.2545, -0.9148,  1.6746,  0.4740,  0.9441,  0.7761, -0.2691,  0.8501,\n",
      "          0.6651,  0.3766, -0.4681, -1.1881, -1.0985,  1.8772, -1.1190,  1.1074,\n",
      "         -1.2402, -0.4190,  0.9682,  1.0405,  0.4595, -0.4437, -0.4580,  0.8798,\n",
      "         -1.3091,  0.0321,  0.4569, -0.6405, -1.6380, -2.4346,  1.1504, -1.9249,\n",
      "         -3.3822,  0.8449, -0.6874,  0.7737,  1.4565,  0.3875, -0.5562, -1.7945,\n",
      "         -0.7156, -0.7703,  0.6519, -1.1689,  1.0359,  0.3445, -0.2375, -0.9395,\n",
      "          1.1998, -0.4724, -0.8488, -2.3225, -0.4400, -1.5887,  2.2241,  0.1851,\n",
      "         -0.2057,  0.8181,  0.6509,  0.0071, -0.5619, -1.3643,  0.3667, -0.0954,\n",
      "         -1.8079,  0.9513, -1.2197,  0.6994, -0.1013, -1.4179,  0.5921, -0.3848,\n",
      "         -0.7383,  0.1252,  0.7560, -0.8307, -1.1280,  1.4376, -1.8204, -0.9400,\n",
      "          0.1279,  2.4130, -0.2988, -0.6461, -1.8423,  2.2112, -1.5699, -1.4928,\n",
      "          1.5449,  0.7160,  0.2613,  0.6241, -1.1815, -1.1345,  0.2688, -0.8882,\n",
      "         -0.5449, -0.4567,  0.0513,  0.0610,  0.0214, -0.2250,  0.0191, -1.6119,\n",
      "          0.5573,  0.1757,  1.0145,  0.8286,  0.4070,  1.3152, -0.4989, -0.8352,\n",
      "          0.6483,  1.8972, -0.9577,  0.3563, -0.9919, -0.6298,  1.0070, -0.7918,\n",
      "         -0.3036, -0.3720, -0.9147, -2.0048, -0.0255,  0.5021,  0.6501,  0.4674,\n",
      "          0.8875, -0.3458,  1.6261,  0.2259,  0.9777, -0.4382,  0.1792, -1.1413,\n",
      "         -1.1066,  1.1037, -0.0974,  1.8774,  1.0612, -2.2033, -0.2759, -0.3804,\n",
      "          0.4923,  1.1269,  0.6625, -1.2815, -0.4531, -0.3741,  1.2034,  1.1234,\n",
      "         -2.5083,  0.7234,  0.6228, -1.1632,  1.0706,  0.4333,  0.1572, -0.2035,\n",
      "         -0.5357,  0.5104, -0.3167,  2.4474, -1.0832,  0.7906,  0.2175, -0.1912,\n",
      "         -0.0581, -0.2205,  0.8144,  0.0169, -0.4812,  0.2724, -0.4105, -0.3557,\n",
      "         -1.3927,  0.0036,  0.3264, -0.9070,  0.9234,  0.1841,  1.3641,  0.5800,\n",
      "          0.6133, -0.8920,  0.9310, -0.8607,  0.7917,  0.4237, -0.1704, -0.2628,\n",
      "         -1.7601, -0.1574, -0.9611,  0.6279,  0.4354,  0.9700,  0.1513, -0.7090,\n",
      "         -1.9428,  1.5451, -0.4251, -0.7012,  0.2142, -0.2875, -1.3703, -0.3762,\n",
      "         -0.2692,  0.6226,  0.7449,  0.7119,  0.4542,  0.5831, -1.9731, -1.4229,\n",
      "          0.8558, -0.6636, -2.4088, -0.1229, -0.2121,  1.9402, -0.9051, -0.1224,\n",
      "          1.1667, -0.1156, -1.0334,  0.7043, -0.5652,  0.0822, -0.5090,  0.1921,\n",
      "          0.5672, -0.8900,  0.8923,  0.1574,  2.1810, -2.3379,  0.4744, -0.2655,\n",
      "          0.9321,  0.0249,  0.2187, -0.2907, -0.0911, -2.1294,  1.6117,  0.0966,\n",
      "          0.4283, -0.0653,  0.8470,  1.1618,  1.2900,  1.8091, -0.5600, -0.8878,\n",
      "          0.6598, -1.0321, -0.9852, -0.1149, -1.2306,  0.1404,  0.3834,  0.3172,\n",
      "         -0.1792, -1.3634, -0.4721, -1.3057, -0.6653, -1.8017, -1.8396,  2.0021,\n",
      "         -1.3233,  2.2394,  0.6456,  0.7351, -1.7668, -0.4400, -1.3721, -0.0035,\n",
      "         -0.5328,  0.5351,  0.0063,  2.3088, -0.7474, -0.8368, -1.6395, -0.7920,\n",
      "         -0.3294,  1.0427, -0.9346,  1.1568, -1.0637, -0.2054,  1.1424, -0.1476,\n",
      "          0.1238,  0.4925,  0.8562, -2.2229,  0.4841, -0.5297, -0.0548, -1.3044,\n",
      "         -0.0655, -0.1536,  0.3220,  0.9895,  2.6169,  0.0147, -0.5016, -0.7385,\n",
      "          1.6413, -1.2102, -0.0078, -2.3696,  1.0585, -1.4638, -0.2978,  0.9471,\n",
      "          0.4860, -0.5105, -0.1724,  0.1900,  0.8454,  0.2503,  0.7725, -0.4179,\n",
      "         -1.1820,  0.2972,  0.4502,  0.1496, -0.1650, -0.2921,  0.4091, -0.0789,\n",
      "          1.1820,  1.1567, -1.2877,  1.6535,  2.6437,  0.5769,  0.8594, -0.7028,\n",
      "         -1.0556,  0.2354, -0.6079, -1.2631,  0.6525, -0.0883, -1.1667, -0.1829,\n",
      "         -0.9876,  1.5880, -0.8026, -0.2368, -0.0187,  0.3122,  0.2006,  0.9216,\n",
      "         -1.2016,  1.1122,  0.2294, -0.5406, -0.9293, -2.5038, -1.1780,  0.2819,\n",
      "          1.5778,  1.4813, -0.4774,  0.7843,  0.9336, -0.6602, -0.4141,  0.5221,\n",
      "          0.0858, -0.2925, -0.1825,  0.8504,  1.7414, -0.4423, -1.5778,  1.7959,\n",
      "          0.0938,  0.7452,  2.5964, -0.3042, -1.4181,  0.1357,  0.6241,  2.7360,\n",
      "         -1.0779, -0.3610, -0.6062,  0.4227,  0.2253,  0.3340,  1.8179,  1.3886,\n",
      "          0.7029, -3.3081,  1.9290,  0.2054, -0.6097, -0.4876,  1.9912, -0.5271,\n",
      "         -0.2076, -1.3580,  0.8599, -0.9657,  0.8806,  1.4076, -0.6410,  0.2386,\n",
      "         -0.9551,  0.9285,  0.8641, -0.0127,  0.4127,  0.3736, -0.4682,  0.5221,\n",
      "          0.9765,  0.5330, -0.5530,  0.9393, -0.1462, -0.4058, -0.4669,  0.2445,\n",
      "         -1.1569,  0.9856, -1.3994,  0.5778, -0.4249,  0.3061,  1.2663,  0.0820,\n",
      "          0.5014,  0.0487,  1.8316, -0.5230,  1.8219,  1.6737,  1.6377,  0.6854,\n",
      "          0.2874,  0.8412, -0.0983, -0.4573, -0.1889, -0.1245, -1.0582,  1.7954,\n",
      "          0.1398, -0.3381,  1.3967, -0.0273, -0.9918,  0.6765, -0.4145, -0.9027,\n",
      "         -0.7398, -0.1770,  0.9421,  0.0217,  0.9107,  0.3187,  0.8872, -0.6592,\n",
      "         -0.5127, -0.1378,  2.4585, -0.6921, -1.4286,  0.6600,  0.5213,  0.9789,\n",
      "         -0.2304,  0.9187, -0.4171, -0.7016,  1.4888, -0.2203, -0.8421, -2.0081,\n",
      "          0.2840, -0.5002,  1.2553, -0.3851, -0.0655,  0.7874,  1.8405, -1.0688,\n",
      "         -0.6635,  1.5084,  0.1818,  0.5969,  1.6600, -0.3256, -1.0711, -0.9827,\n",
      "         -1.6477,  0.9321,  0.4239, -0.4546,  0.3871,  0.2427, -2.1464, -0.8586,\n",
      "          1.3566, -0.9797,  0.9973, -0.2456,  1.6298, -0.6677, -1.2457,  0.7792,\n",
      "         -0.2317, -0.2419,  1.4567,  0.0817, -0.1062, -0.6798, -0.7621,  0.1394,\n",
      "          1.8282, -0.6867,  0.6894, -0.3227, -1.4762, -0.7650, -1.7895, -1.7102,\n",
      "          1.3472, -1.2569, -1.0840,  0.5527,  0.2508, -1.3422,  0.7743,  1.1883,\n",
      "         -0.0483, -0.6589, -0.1038,  1.1571,  0.8177, -2.1923,  1.6667,  0.5801,\n",
      "          1.1205,  0.7923,  0.3245, -1.9914, -0.5902,  0.4578,  0.3590,  2.1062,\n",
      "         -0.1796, -0.1106,  0.1662, -0.1436, -0.8147,  0.5969, -0.4943,  0.0618,\n",
      "         -0.0097,  1.3726, -0.1758,  1.2559,  1.0264, -0.2395,  1.1915,  1.5418,\n",
      "          1.6222, -0.2900,  0.4573,  0.3903, -0.1773, -0.7980,  0.6356, -0.1418,\n",
      "         -0.6189,  0.8017, -1.1620, -0.0486, -0.0485,  0.6088, -0.0352,  0.6012,\n",
      "          0.5390, -0.4528,  0.9192,  0.8272,  0.3000,  0.4812,  1.1186,  0.0215,\n",
      "         -1.0817, -1.5068,  0.6584,  0.2030, -0.2664,  1.0196, -1.3616, -1.5543,\n",
      "          1.4240,  0.8878, -0.0340, -2.5750, -2.6090,  0.1656,  0.9616,  0.5252,\n",
      "         -2.4149, -1.9915,  1.0953,  0.9952, -0.2112,  0.7993, -0.9326, -0.1816,\n",
      "         -0.8424,  0.6044,  1.5917, -1.4969,  1.4307,  2.0192,  2.0551, -0.5666,\n",
      "         -0.0697,  0.3332, -1.5929,  0.7521, -0.0395,  1.7304, -0.4245,  0.4265,\n",
      "         -1.1998, -0.6017,  2.2155,  0.4595, -0.0913,  0.9895,  1.1203,  1.0505,\n",
      "         -1.4598, -0.2440, -1.3899,  1.0795, -0.0424,  0.6475, -2.5374, -0.2405]],\n",
      "       device='cuda:0')\n",
      "x tensor([[-0.2405, -2.5374,  0.6475, -0.0424,  1.0795, -1.3899, -0.2440, -1.4598,\n",
      "          1.0505,  1.1203,  0.9895, -0.0913,  0.4595,  2.2155, -0.6017, -1.1998,\n",
      "          0.4265, -0.4245,  1.7304, -0.0395,  0.7521, -1.5929,  0.3332, -0.0697,\n",
      "         -0.5666,  2.0551,  2.0192,  1.4307, -1.4969,  1.5917,  0.6044, -0.8424,\n",
      "         -0.1816, -0.9326,  0.7993, -0.2112,  0.9952,  1.0953, -1.9915, -2.4149,\n",
      "          0.5252,  0.9616,  0.1656, -2.6090, -2.5750, -0.0340,  0.8878,  1.4240,\n",
      "         -1.5543, -1.3616,  1.0196, -0.2664,  0.2030,  0.6584, -1.5068, -1.0817,\n",
      "          0.0215,  1.1186,  0.4812,  0.3000,  0.8272,  0.9192, -0.4528,  0.5390,\n",
      "          0.6012, -0.0352,  0.6088, -0.0485, -0.0486, -1.1620,  0.8017, -0.6189,\n",
      "         -0.1418,  0.6356, -0.7980, -0.1773,  0.3903,  0.4573, -0.2900,  1.6222,\n",
      "          1.5418,  1.1915, -0.2395,  1.0264,  1.2559, -0.1758,  1.3726, -0.0097,\n",
      "          0.0618, -0.4943,  0.5969, -0.8147, -0.1436,  0.1662, -0.1106, -0.1796,\n",
      "          2.1062,  0.3590,  0.4578, -0.5902, -1.9914,  0.3245,  0.7923,  1.1205,\n",
      "          0.5801,  1.6667, -2.1923,  0.8177,  1.1571, -0.1038, -0.6589, -0.0483,\n",
      "          1.1883,  0.7743, -1.3422,  0.2508,  0.5527, -1.0840, -1.2569,  1.3472,\n",
      "         -1.7102, -1.7895, -0.7650, -1.4762, -0.3227,  0.6894, -0.6867,  1.8282,\n",
      "          0.1394, -0.7621, -0.6798, -0.1062,  0.0817,  1.4567, -0.2419, -0.2317,\n",
      "          0.7792, -1.2457, -0.6677,  1.6298, -0.2456,  0.9973, -0.9797,  1.3566,\n",
      "         -0.8586, -2.1464,  0.2427,  0.3871, -0.4546,  0.4239,  0.9321, -1.6477,\n",
      "         -0.9827, -1.0711, -0.3256,  1.6600,  0.5969,  0.1818,  1.5084, -0.6635,\n",
      "         -1.0688,  1.8405,  0.7874, -0.0655, -0.3851,  1.2553, -0.5002,  0.2840,\n",
      "         -2.0081, -0.8421, -0.2203,  1.4888, -0.7016, -0.4171,  0.9187, -0.2304,\n",
      "          0.9789,  0.5213,  0.6600, -1.4286, -0.6921,  2.4585, -0.1378, -0.5127,\n",
      "         -0.6592,  0.8872,  0.3187,  0.9107,  0.0217,  0.9421, -0.1770, -0.7398,\n",
      "         -0.9027, -0.4145,  0.6765, -0.9918, -0.0273,  1.3967, -0.3381,  0.1398,\n",
      "          1.7954, -1.0582, -0.1245, -0.1889, -0.4573, -0.0983,  0.8412,  0.2874,\n",
      "          0.6854,  1.6377,  1.6737,  1.8219, -0.5230,  1.8316,  0.0487,  0.5014,\n",
      "          0.0820,  1.2663,  0.3061, -0.4249,  0.5778, -1.3994,  0.9856, -1.1569,\n",
      "          0.2445, -0.4669, -0.4058, -0.1462,  0.9393, -0.5530,  0.5330,  0.9765,\n",
      "          0.5221, -0.4682,  0.3736,  0.4127, -0.0127,  0.8641,  0.9285, -0.9551,\n",
      "          0.2386, -0.6410,  1.4076,  0.8806, -0.9657,  0.8599, -1.3580, -0.2076,\n",
      "         -0.5271,  1.9912, -0.4876, -0.6097,  0.2054,  1.9290, -3.3081,  0.7029,\n",
      "          1.3886,  1.8179,  0.3340,  0.2253,  0.4227, -0.6062, -0.3610, -1.0779,\n",
      "          2.7360,  0.6241,  0.1357, -1.4181, -0.3042,  2.5964,  0.7452,  0.0938,\n",
      "          1.7959, -1.5778, -0.4423,  1.7414,  0.8504, -0.1825, -0.2925,  0.0858,\n",
      "          0.5221, -0.4141, -0.6602,  0.9336,  0.7843, -0.4774,  1.4813,  1.5778,\n",
      "          0.2819, -1.1780, -2.5038, -0.9293, -0.5406,  0.2294,  1.1122, -1.2016,\n",
      "          0.9216,  0.2006,  0.3122, -0.0187, -0.2368, -0.8026,  1.5880, -0.9876,\n",
      "         -0.1829, -1.1667, -0.0883,  0.6525, -1.2631, -0.6079,  0.2354, -1.0556,\n",
      "         -0.7028,  0.8594,  0.5769,  2.6437,  1.6535, -1.2877,  1.1567,  1.1820,\n",
      "         -0.0789,  0.4091, -0.2921, -0.1650,  0.1496,  0.4502,  0.2972, -1.1820,\n",
      "         -0.4179,  0.7725,  0.2503,  0.8454,  0.1900, -0.1724, -0.5105,  0.4860,\n",
      "          0.9471, -0.2978, -1.4638,  1.0585, -2.3696, -0.0078, -1.2102,  1.6413,\n",
      "         -0.7385, -0.5016,  0.0147,  2.6169,  0.9895,  0.3220, -0.1536, -0.0655,\n",
      "         -1.3044, -0.0548, -0.5297,  0.4841, -2.2229,  0.8562,  0.4925,  0.1238,\n",
      "         -0.1476,  1.1424, -0.2054, -1.0637,  1.1568, -0.9346,  1.0427, -0.3294,\n",
      "         -0.7920, -1.6395, -0.8368, -0.7474,  2.3088,  0.0063,  0.5351, -0.5328,\n",
      "         -0.0035, -1.3721, -0.4400, -1.7668,  0.7351,  0.6456,  2.2394, -1.3233,\n",
      "          2.0021, -1.8396, -1.8017, -0.6653, -1.3057, -0.4721, -1.3634, -0.1792,\n",
      "          0.3172,  0.3834,  0.1404, -1.2306, -0.1149, -0.9852, -1.0321,  0.6598,\n",
      "         -0.8878, -0.5600,  1.8091,  1.2900,  1.1618,  0.8470, -0.0653,  0.4283,\n",
      "          0.0966,  1.6117, -2.1294, -0.0911, -0.2907,  0.2187,  0.0249,  0.9321,\n",
      "         -0.2655,  0.4744, -2.3379,  2.1810,  0.1574,  0.8923, -0.8900,  0.5672,\n",
      "          0.1921, -0.5090,  0.0822, -0.5652,  0.7043, -1.0334, -0.1156,  1.1667,\n",
      "         -0.1224, -0.9051,  1.9402, -0.2121, -0.1229, -2.4088, -0.6636,  0.8558,\n",
      "         -1.4229, -1.9731,  0.5831,  0.4542,  0.7119,  0.7449,  0.6226, -0.2692,\n",
      "         -0.3762, -1.3703, -0.2875,  0.2142, -0.7012, -0.4251,  1.5451, -1.9428,\n",
      "         -0.7090,  0.1513,  0.9700,  0.4354,  0.6279, -0.9611, -0.1574, -1.7601,\n",
      "         -0.2628, -0.1704,  0.4237,  0.7917, -0.8607,  0.9310, -0.8920,  0.6133,\n",
      "          0.5800,  1.3641,  0.1841,  0.9234, -0.9070,  0.3264,  0.0036, -1.3927,\n",
      "         -0.3557, -0.4105,  0.2724, -0.4812,  0.0169,  0.8144, -0.2205, -0.0581,\n",
      "         -0.1912,  0.2175,  0.7906, -1.0832,  2.4474, -0.3167,  0.5104, -0.5357,\n",
      "         -0.2035,  0.1572,  0.4333,  1.0706, -1.1632,  0.6228,  0.7234, -2.5083,\n",
      "          1.1234,  1.2034, -0.3741, -0.4531, -1.2815,  0.6625,  1.1269,  0.4923,\n",
      "         -0.3804, -0.2759, -2.2033,  1.0612,  1.8774, -0.0974,  1.1037, -1.1066,\n",
      "         -1.1413,  0.1792, -0.4382,  0.9777,  0.2259,  1.6261, -0.3458,  0.8875,\n",
      "          0.4674,  0.6501,  0.5021, -0.0255, -2.0048, -0.9147, -0.3720, -0.3036,\n",
      "         -0.7918,  1.0070, -0.6298, -0.9919,  0.3563, -0.9577,  1.8972,  0.6483,\n",
      "         -0.8352, -0.4989,  1.3152,  0.4070,  0.8286,  1.0145,  0.1757,  0.5573,\n",
      "         -1.6119,  0.0191, -0.2250,  0.0214,  0.0610,  0.0513, -0.4567, -0.5449,\n",
      "         -0.8882,  0.2688, -1.1345, -1.1815,  0.6241,  0.2613,  0.7160,  1.5449,\n",
      "         -1.4928, -1.5699,  2.2112, -1.8423, -0.6461, -0.2988,  2.4130,  0.1279,\n",
      "         -0.9400, -1.8204,  1.4376, -1.1280, -0.8307,  0.7560,  0.1252, -0.7383,\n",
      "         -0.3848,  0.5921, -1.4179, -0.1013,  0.6994, -1.2197,  0.9513, -1.8079,\n",
      "         -0.0954,  0.3667, -1.3643, -0.5619,  0.0071,  0.6509,  0.8181, -0.2057,\n",
      "          0.1851,  2.2241, -1.5887, -0.4400, -2.3225, -0.8488, -0.4724,  1.1998,\n",
      "         -0.9395, -0.2375,  0.3445,  1.0359, -1.1689,  0.6519, -0.7703, -0.7156,\n",
      "         -1.7945, -0.5562,  0.3875,  1.4565,  0.7737, -0.6874,  0.8449, -3.3822,\n",
      "         -1.9249,  1.1504, -2.4346, -1.6380, -0.6405,  0.4569,  0.0321, -1.3091,\n",
      "          0.8798, -0.4580, -0.4437,  0.4595,  1.0405,  0.9682, -0.4190, -1.2402,\n",
      "          1.1074, -1.1190,  1.8772, -1.0985, -1.1881, -0.4681,  0.3766,  0.6651,\n",
      "          0.8501, -0.2691,  0.7761,  0.9441,  0.4740,  1.6746, -0.9148, -0.2545,\n",
      "          1.2996,  0.3400,  0.5687,  0.4200,  1.7453,  0.8338,  0.1579,  1.0184,\n",
      "         -2.5834, -1.1517,  0.6409,  1.3478, -0.7985,  0.8594,  1.1352, -1.5245,\n",
      "         -2.1239,  2.0533, -0.0073,  0.1924,  1.2724, -0.6596, -1.1874, -1.5544,\n",
      "         -2.6664,  0.1381, -0.1761, -1.1694,  1.1908,  0.5947, -0.3165, -0.0357,\n",
      "         -0.7929, -0.1321, -0.4034, -0.1490,  0.6683,  1.2615,  0.1032, -0.6891,\n",
      "          1.3105, -0.1500,  0.0728, -1.0258, -0.3877,  0.1759, -0.4285,  0.0166,\n",
      "         -1.1655,  0.0069,  0.7777,  1.7642,  0.7348,  0.1870, -0.4333,  0.0844,\n",
      "          0.0906,  0.0462, -0.1970, -1.8379,  0.8128, -1.0843, -2.5885, -0.7533,\n",
      "          1.5701, -0.6973, -0.3857, -0.2700, -1.6795,  1.0936,  1.0811,  2.4245,\n",
      "          0.7474,  0.2615, -0.2119,  1.7163, -0.3497,  0.6425,  0.5940,  0.2345,\n",
      "          1.6248,  1.7075,  0.5232,  0.2288, -0.2886, -0.2070, -1.0579,  0.1564,\n",
      "         -0.3857, -0.6663,  1.0760,  0.0895, -0.8622, -2.0383,  0.6050, -0.2709,\n",
      "          1.8780, -0.0322,  1.8578, -1.2885,  0.7243, -0.0792, -0.4943, -0.6851,\n",
      "         -0.6254,  0.3823, -0.4863, -1.1269,  0.0117, -0.6853,  0.7798, -0.4127,\n",
      "         -0.0733,  0.1750,  0.6377,  1.2084,  0.2955, -1.8159, -0.5826, -2.6576,\n",
      "         -1.1649,  1.8860, -0.9484, -0.9269, -0.2257,  0.1683,  0.2927, -2.0968]],\n",
      "       device='cuda:0')\n",
      "y tensor([[-0.2405, -2.5374,  0.6475, -0.0424,  1.0795, -1.3899, -0.2440, -1.4598,\n",
      "          1.0505,  1.1203,  0.9895, -0.0913,  0.4595,  2.2155, -0.6017, -1.1998,\n",
      "          0.4265, -0.4245,  1.7304, -0.0395,  0.7521, -1.5929,  0.3332, -0.0697,\n",
      "         -0.5666,  2.0551,  2.0192,  1.4307, -1.4969,  1.5917,  0.6044, -0.8424,\n",
      "         -0.1816, -0.9326,  0.7993, -0.2112,  0.9952,  1.0953, -1.9915, -2.4149,\n",
      "          0.5252,  0.9616,  0.1656, -2.6090, -2.5750, -0.0340,  0.8878,  1.4240,\n",
      "         -1.5543, -1.3616,  1.0196, -0.2664,  0.2030,  0.6584, -1.5068, -1.0817,\n",
      "          0.0215,  1.1186,  0.4812,  0.3000,  0.8272,  0.9192, -0.4528,  0.5390,\n",
      "          0.6012, -0.0352,  0.6088, -0.0485, -0.0486, -1.1620,  0.8017, -0.6189,\n",
      "         -0.1418,  0.6356, -0.7980, -0.1773,  0.3903,  0.4573, -0.2900,  1.6222,\n",
      "          1.5418,  1.1915, -0.2395,  1.0264,  1.2559, -0.1758,  1.3726, -0.0097,\n",
      "          0.0618, -0.4943,  0.5969, -0.8147, -0.1436,  0.1662, -0.1106, -0.1796,\n",
      "          2.1062,  0.3590,  0.4578, -0.5902, -1.9914,  0.3245,  0.7923,  1.1205,\n",
      "          0.5801,  1.6667, -2.1923,  0.8177,  1.1571, -0.1038, -0.6589, -0.0483,\n",
      "          1.1883,  0.7743, -1.3422,  0.2508,  0.5527, -1.0840, -1.2569,  1.3472,\n",
      "         -1.7102, -1.7895, -0.7650, -1.4762, -0.3227,  0.6894, -0.6867,  1.8282,\n",
      "          0.1394, -0.7621, -0.6798, -0.1062,  0.0817,  1.4567, -0.2419, -0.2317,\n",
      "          0.7792, -1.2457, -0.6677,  1.6298, -0.2456,  0.9973, -0.9797,  1.3566,\n",
      "         -0.8586, -2.1464,  0.2427,  0.3871, -0.4546,  0.4239,  0.9321, -1.6477,\n",
      "         -0.9827, -1.0711, -0.3256,  1.6600,  0.5969,  0.1818,  1.5084, -0.6635,\n",
      "         -1.0688,  1.8405,  0.7874, -0.0655, -0.3851,  1.2553, -0.5002,  0.2840,\n",
      "         -2.0081, -0.8421, -0.2203,  1.4888, -0.7016, -0.4171,  0.9187, -0.2304,\n",
      "          0.9789,  0.5213,  0.6600, -1.4286, -0.6921,  2.4585, -0.1378, -0.5127,\n",
      "         -0.6592,  0.8872,  0.3187,  0.9107,  0.0217,  0.9421, -0.1770, -0.7398,\n",
      "         -0.9027, -0.4145,  0.6765, -0.9918, -0.0273,  1.3967, -0.3381,  0.1398,\n",
      "          1.7954, -1.0582, -0.1245, -0.1889, -0.4573, -0.0983,  0.8412,  0.2874,\n",
      "          0.6854,  1.6377,  1.6737,  1.8219, -0.5230,  1.8316,  0.0487,  0.5014,\n",
      "          0.0820,  1.2663,  0.3061, -0.4249,  0.5778, -1.3994,  0.9856, -1.1569,\n",
      "          0.2445, -0.4669, -0.4058, -0.1462,  0.9393, -0.5530,  0.5330,  0.9765,\n",
      "          0.5221, -0.4682,  0.3736,  0.4127, -0.0127,  0.8641,  0.9285, -0.9551,\n",
      "          0.2386, -0.6410,  1.4076,  0.8806, -0.9657,  0.8599, -1.3580, -0.2076,\n",
      "         -0.5271,  1.9912, -0.4876, -0.6097,  0.2054,  1.9290, -3.3081,  0.7029,\n",
      "          1.3886,  1.8179,  0.3340,  0.2253,  0.4227, -0.6062, -0.3610, -1.0779,\n",
      "          2.7360,  0.6241,  0.1357, -1.4181, -0.3042,  2.5964,  0.7452,  0.0938,\n",
      "          1.7959, -1.5778, -0.4423,  1.7414,  0.8504, -0.1825, -0.2925,  0.0858,\n",
      "          0.5221, -0.4141, -0.6602,  0.9336,  0.7843, -0.4774,  1.4813,  1.5778,\n",
      "          0.2819, -1.1780, -2.5038, -0.9293, -0.5406,  0.2294,  1.1122, -1.2016,\n",
      "          0.9216,  0.2006,  0.3122, -0.0187, -0.2368, -0.8026,  1.5880, -0.9876,\n",
      "         -0.1829, -1.1667, -0.0883,  0.6525, -1.2631, -0.6079,  0.2354, -1.0556,\n",
      "         -0.7028,  0.8594,  0.5769,  2.6437,  1.6535, -1.2877,  1.1567,  1.1820,\n",
      "         -0.0789,  0.4091, -0.2921, -0.1650,  0.1496,  0.4502,  0.2972, -1.1820,\n",
      "         -0.4179,  0.7725,  0.2503,  0.8454,  0.1900, -0.1724, -0.5105,  0.4860,\n",
      "          0.9471, -0.2978, -1.4638,  1.0585, -2.3696, -0.0078, -1.2102,  1.6413,\n",
      "         -0.7385, -0.5016,  0.0147,  2.6169,  0.9895,  0.3220, -0.1536, -0.0655,\n",
      "         -1.3044, -0.0548, -0.5297,  0.4841, -2.2229,  0.8562,  0.4925,  0.1238,\n",
      "         -0.1476,  1.1424, -0.2054, -1.0637,  1.1568, -0.9346,  1.0427, -0.3294,\n",
      "         -0.7920, -1.6395, -0.8368, -0.7474,  2.3088,  0.0063,  0.5351, -0.5328,\n",
      "         -0.0035, -1.3721, -0.4400, -1.7668,  0.7351,  0.6456,  2.2394, -1.3233,\n",
      "          2.0021, -1.8396, -1.8017, -0.6653, -1.3057, -0.4721, -1.3634, -0.1792,\n",
      "          0.3867,  0.3668,  0.0856, -1.2649, -0.0859, -0.9223, -1.0936,  0.6769,\n",
      "         -1.0555, -0.6391,  1.9158,  1.2773,  1.1601,  0.8330, -0.0417,  0.4016,\n",
      "          0.1309,  1.6499, -2.0194, -0.1272, -0.2417,  0.2621,  0.0202,  0.9173,\n",
      "         -0.2888,  0.4499, -2.4996,  2.1804,  0.1802,  0.9253, -0.9350,  0.5684,\n",
      "          0.1820, -0.5124,  0.0943, -0.6207,  0.7000, -1.0335, -0.0717,  1.1428,\n",
      "         -0.1165, -0.9532,  1.9204, -0.2078, -0.0921, -2.3229, -0.6665,  0.9786,\n",
      "         -1.4200, -1.8845,  0.6338,  0.4233,  0.7797,  0.7497,  0.5916, -0.2626,\n",
      "         -0.4250, -1.4104, -0.2432,  0.2028, -0.7414, -0.4585,  1.5736, -1.7669,\n",
      "         -0.6812,  0.0864,  1.0565,  0.4458,  0.6225, -0.8513, -0.1912, -1.8283,\n",
      "         -0.3078, -0.1809,  0.3848,  0.6901, -0.8187,  1.0221, -0.8887,  0.6409,\n",
      "          0.5991,  1.4826,  0.1726,  0.9200, -0.8249,  0.3616,  0.0321, -1.4083,\n",
      "         -0.3622, -0.4641,  0.2663, -0.4054, -0.0432,  0.7835, -0.2651, -0.1426,\n",
      "         -0.2243,  0.1573,  0.7876, -1.0679,  2.3755, -0.2787,  0.4467, -0.5455,\n",
      "         -0.1516,  0.1507,  0.4288,  1.1138, -1.3527,  0.5289,  0.8165, -2.5810,\n",
      "          1.1520,  1.1018, -0.3042, -0.4566, -1.3518,  0.6468,  1.0641,  0.5438,\n",
      "         -0.3569, -0.3620, -2.2422,  1.0791,  1.9767, -0.1201,  1.1018, -1.1101,\n",
      "         -1.1709,  0.2108, -0.4331,  1.0245,  0.2855,  1.6278, -0.4472,  0.9015,\n",
      "          0.4867,  0.5768,  0.5182, -0.0420, -1.8813, -0.8805, -0.4425, -0.2692,\n",
      "         -0.8465,  0.9978, -0.6999, -1.0220,  0.3672, -0.9138,  1.8294,  0.6543,\n",
      "         -0.8035, -0.5607,  1.2478,  0.4684,  0.8265,  1.0037,  0.2029,  0.4903,\n",
      "         -1.6691,  0.0236, -0.1568,  0.0370,  0.0066,  0.0312, -0.4695, -0.5207,\n",
      "         -0.8096,  0.2954, -1.0595, -1.2435,  0.7058,  0.2461,  0.8047,  1.5242,\n",
      "         -1.6765, -1.4888,  2.1201, -1.8550, -0.5974, -0.3234,  2.4115,  0.1032,\n",
      "         -0.8914, -1.8760,  1.4538, -1.2219, -0.8027,  0.7021,  0.0916, -0.6725,\n",
      "         -0.4241,  0.5761, -1.3892, -0.0753,  0.7167, -1.2120,  0.9418, -1.6441,\n",
      "         -0.1743,  0.3101, -1.2381, -0.5210, -0.0155,  0.6819,  0.7459, -0.1974,\n",
      "          0.2083,  2.1312, -1.5338, -0.4019, -2.2302, -0.7467, -0.5073,  1.1986,\n",
      "         -0.9958, -0.3034,  0.3736,  0.9879, -1.1351,  0.6951, -0.8381, -0.6677,\n",
      "         -1.8244, -0.5840,  0.4652,  1.5051,  0.7668, -0.6738,  0.7551, -3.4950,\n",
      "         -1.9012,  1.0640, -2.4375, -1.6005, -0.6423,  0.5303,  0.0379, -1.4067,\n",
      "          0.7756, -0.5062, -0.4563,  0.4471,  1.1248,  1.0047, -0.4172, -1.3044,\n",
      "          1.1732, -1.2369,  2.0204, -1.2537, -1.1182, -0.4308,  0.3741,  0.6243,\n",
      "          0.8201, -0.2413,  0.7304,  1.0545,  0.5433,  1.7023, -0.9962, -0.3479,\n",
      "          1.3150,  0.3436,  0.5875,  0.3497,  1.6663,  0.8212,  0.1953,  0.9382,\n",
      "         -2.6526, -1.1957,  0.5357,  1.4041, -0.7932,  0.9153,  1.1221, -1.4776,\n",
      "         -2.1492,  2.0354,  0.0049,  0.1913,  1.3567, -0.5697, -1.1405, -1.5352,\n",
      "         -2.4449,  0.0866, -0.1508, -1.1815,  1.1896,  0.5710, -0.3021, -0.0509,\n",
      "         -0.8808, -0.0815, -0.3694, -0.1607,  0.6565,  1.2956,  0.1325, -0.6847,\n",
      "          1.3732, -0.1172,  0.0291, -1.1001, -0.3978,  0.1601, -0.2864,  0.0291,\n",
      "         -1.0829,  0.0082,  0.8229,  1.7472,  0.6973,  0.2918, -0.4232,  0.1234,\n",
      "          0.0417,  0.0646, -0.1478, -1.8177,  0.8956, -1.1406, -2.5324, -0.7141,\n",
      "          1.5470, -0.7125, -0.2639, -0.3170, -1.8411,  1.0543,  1.0580,  2.5340,\n",
      "          0.6545,  0.3110, -0.2499,  1.7143, -0.3414,  0.5848,  0.5774,  0.2457,\n",
      "          1.6481,  1.7730,  0.5312,  0.2103, -0.2109, -0.2788, -1.0616,  0.1532,\n",
      "         -0.3694, -0.5945,  1.1114,  0.0726, -0.9278, -2.0433,  0.6349, -0.3290,\n",
      "          1.9695, -0.0173,  1.8659, -1.4665,  0.6507, -0.0890, -0.5669, -0.6868,\n",
      "         -0.6216,  0.4380, -0.4508, -1.1043,  0.0906, -0.6973,  0.7043, -0.4090,\n",
      "         -0.0485,  0.1647,  0.6929,  1.1551,  0.2020, -1.8066, -0.6247, -2.7898,\n",
      "         -1.2061,  1.7048, -1.0357, -1.0643, -0.2642,  0.1163,  0.3402, -2.3410]],\n",
      "       device='cuda:0')\n",
      "x tensor([[-2.3410,  0.3402,  0.1163, -0.2642, -1.0643, -1.0357,  1.7048, -1.2061,\n",
      "         -2.7898, -0.6247, -1.8066,  0.2020,  1.1551,  0.6929,  0.1647, -0.0485,\n",
      "         -0.4090,  0.7043, -0.6973,  0.0906, -1.1043, -0.4508,  0.4380, -0.6216,\n",
      "         -0.6868, -0.5669, -0.0890,  0.6507, -1.4665,  1.8659, -0.0173,  1.9695,\n",
      "         -0.3290,  0.6349, -2.0433, -0.9278,  0.0726,  1.1114, -0.5945, -0.3694,\n",
      "          0.1532, -1.0616, -0.2788, -0.2109,  0.2103,  0.5312,  1.7730,  1.6481,\n",
      "          0.2457,  0.5774,  0.5848, -0.3414,  1.7143, -0.2499,  0.3110,  0.6545,\n",
      "          2.5340,  1.0580,  1.0543, -1.8411, -0.3170, -0.2639, -0.7125,  1.5470,\n",
      "         -0.7141, -2.5324, -1.1406,  0.8956, -1.8177, -0.1478,  0.0646,  0.0417,\n",
      "          0.1234, -0.4232,  0.2918,  0.6973,  1.7472,  0.8229,  0.0082, -1.0829,\n",
      "          0.0291, -0.2864,  0.1601, -0.3978, -1.1001,  0.0291, -0.1172,  1.3732,\n",
      "         -0.6847,  0.1325,  1.2956,  0.6565, -0.1607, -0.3694, -0.0815, -0.8808,\n",
      "         -0.0509, -0.3021,  0.5710,  1.1896, -1.1815, -0.1508,  0.0866, -2.4449,\n",
      "         -1.5352, -1.1405, -0.5697,  1.3567,  0.1913,  0.0049,  2.0354, -2.1492,\n",
      "         -1.4776,  1.1221,  0.9153, -0.7932,  1.4041,  0.5357, -1.1957, -2.6526,\n",
      "          0.9382,  0.1953,  0.8212,  1.6663,  0.3497,  0.5875,  0.3436,  1.3150,\n",
      "         -0.3479, -0.9962,  1.7023,  0.5433,  1.0545,  0.7304, -0.2413,  0.8201,\n",
      "          0.6243,  0.3741, -0.4308, -1.1182, -1.2537,  2.0204, -1.2369,  1.1732,\n",
      "         -1.3044, -0.4172,  1.0047,  1.1248,  0.4471, -0.4563, -0.5062,  0.7756,\n",
      "         -1.4067,  0.0379,  0.5303, -0.6423, -1.6005, -2.4375,  1.0640, -1.9012,\n",
      "         -3.4950,  0.7551, -0.6738,  0.7668,  1.5051,  0.4652, -0.5840, -1.8244,\n",
      "         -0.6677, -0.8381,  0.6951, -1.1351,  0.9879,  0.3736, -0.3034, -0.9958,\n",
      "          1.1986, -0.5073, -0.7467, -2.2302, -0.4019, -1.5338,  2.1312,  0.2083,\n",
      "         -0.1974,  0.7459,  0.6819, -0.0155, -0.5210, -1.2381,  0.3101, -0.1743,\n",
      "         -1.6441,  0.9418, -1.2120,  0.7167, -0.0753, -1.3892,  0.5761, -0.4241,\n",
      "         -0.6725,  0.0916,  0.7021, -0.8027, -1.2219,  1.4538, -1.8760, -0.8914,\n",
      "          0.1032,  2.4115, -0.3234, -0.5974, -1.8550,  2.1201, -1.4888, -1.6765,\n",
      "          1.5242,  0.8047,  0.2461,  0.7058, -1.2435, -1.0595,  0.2954, -0.8096,\n",
      "         -0.5207, -0.4695,  0.0312,  0.0066,  0.0370, -0.1568,  0.0236, -1.6691,\n",
      "          0.4903,  0.2029,  1.0037,  0.8265,  0.4684,  1.2478, -0.5607, -0.8035,\n",
      "          0.6543,  1.8294, -0.9138,  0.3672, -1.0220, -0.6999,  0.9978, -0.8465,\n",
      "         -0.2692, -0.4425, -0.8805, -1.8813, -0.0420,  0.5182,  0.5768,  0.4867,\n",
      "          0.9015, -0.4472,  1.6278,  0.2855,  1.0245, -0.4331,  0.2108, -1.1709,\n",
      "         -1.1101,  1.1018, -0.1201,  1.9767,  1.0791, -2.2422, -0.3620, -0.3569,\n",
      "          0.5438,  1.0641,  0.6468, -1.3518, -0.4566, -0.3042,  1.1018,  1.1520,\n",
      "         -2.5810,  0.8165,  0.5289, -1.3527,  1.1138,  0.4288,  0.1507, -0.1516,\n",
      "         -0.5455,  0.4467, -0.2787,  2.3755, -1.0679,  0.7876,  0.1573, -0.2243,\n",
      "         -0.1426, -0.2651,  0.7835, -0.0432, -0.4054,  0.2663, -0.4641, -0.3622,\n",
      "         -1.4083,  0.0321,  0.3616, -0.8249,  0.9200,  0.1726,  1.4826,  0.5991,\n",
      "          0.6409, -0.8887,  1.0221, -0.8187,  0.6901,  0.3848, -0.1809, -0.3078,\n",
      "         -1.8283, -0.1912, -0.8513,  0.6225,  0.4458,  1.0565,  0.0864, -0.6812,\n",
      "         -1.7669,  1.5736, -0.4585, -0.7414,  0.2028, -0.2432, -1.4104, -0.4250,\n",
      "         -0.2626,  0.5916,  0.7497,  0.7797,  0.4233,  0.6338, -1.8845, -1.4200,\n",
      "          0.9786, -0.6665, -2.3229, -0.0921, -0.2078,  1.9204, -0.9532, -0.1165,\n",
      "          1.1428, -0.0717, -1.0335,  0.7000, -0.6207,  0.0943, -0.5124,  0.1820,\n",
      "          0.5684, -0.9350,  0.9253,  0.1802,  2.1804, -2.4996,  0.4499, -0.2888,\n",
      "          0.9173,  0.0202,  0.2621, -0.2417, -0.1272, -2.0194,  1.6499,  0.1309,\n",
      "          0.4016, -0.0417,  0.8330,  1.1601,  1.2773,  1.9158, -0.6391, -1.0555,\n",
      "          0.6769, -1.0936, -0.9223, -0.0859, -1.2649,  0.0856,  0.3668,  0.3867,\n",
      "         -0.1792, -1.3634, -0.4721, -1.3057, -0.6653, -1.8017, -1.8396,  2.0021,\n",
      "         -1.3233,  2.2394,  0.6456,  0.7351, -1.7668, -0.4400, -1.3721, -0.0035,\n",
      "         -0.5328,  0.5351,  0.0063,  2.3088, -0.7474, -0.8368, -1.6395, -0.7920,\n",
      "         -0.3294,  1.0427, -0.9346,  1.1568, -1.0637, -0.2054,  1.1424, -0.1476,\n",
      "          0.1238,  0.4925,  0.8562, -2.2229,  0.4841, -0.5297, -0.0548, -1.3044,\n",
      "         -0.0655, -0.1536,  0.3220,  0.9895,  2.6169,  0.0147, -0.5016, -0.7385,\n",
      "          1.6413, -1.2102, -0.0078, -2.3696,  1.0585, -1.4638, -0.2978,  0.9471,\n",
      "          0.4860, -0.5105, -0.1724,  0.1900,  0.8454,  0.2503,  0.7725, -0.4179,\n",
      "         -1.1820,  0.2972,  0.4502,  0.1496, -0.1650, -0.2921,  0.4091, -0.0789,\n",
      "          1.1820,  1.1567, -1.2877,  1.6535,  2.6437,  0.5769,  0.8594, -0.7028,\n",
      "         -1.0556,  0.2354, -0.6079, -1.2631,  0.6525, -0.0883, -1.1667, -0.1829,\n",
      "         -0.9876,  1.5880, -0.8026, -0.2368, -0.0187,  0.3122,  0.2006,  0.9216,\n",
      "         -1.2016,  1.1122,  0.2294, -0.5406, -0.9293, -2.5038, -1.1780,  0.2819,\n",
      "          1.5778,  1.4813, -0.4774,  0.7843,  0.9336, -0.6602, -0.4141,  0.5221,\n",
      "          0.0858, -0.2925, -0.1825,  0.8504,  1.7414, -0.4423, -1.5778,  1.7959,\n",
      "          0.0938,  0.7452,  2.5964, -0.3042, -1.4181,  0.1357,  0.6241,  2.7360,\n",
      "         -1.0779, -0.3610, -0.6062,  0.4227,  0.2253,  0.3340,  1.8179,  1.3886,\n",
      "          0.7029, -3.3081,  1.9290,  0.2054, -0.6097, -0.4876,  1.9912, -0.5271,\n",
      "         -0.2076, -1.3580,  0.8599, -0.9657,  0.8806,  1.4076, -0.6410,  0.2386,\n",
      "         -0.9551,  0.9285,  0.8641, -0.0127,  0.4127,  0.3736, -0.4682,  0.5221,\n",
      "          0.9765,  0.5330, -0.5530,  0.9393, -0.1462, -0.4058, -0.4669,  0.2445,\n",
      "         -1.1569,  0.9856, -1.3994,  0.5778, -0.4249,  0.3061,  1.2663,  0.0820,\n",
      "          0.5014,  0.0487,  1.8316, -0.5230,  1.8219,  1.6737,  1.6377,  0.6854,\n",
      "          0.2874,  0.8412, -0.0983, -0.4573, -0.1889, -0.1245, -1.0582,  1.7954,\n",
      "          0.1398, -0.3381,  1.3967, -0.0273, -0.9918,  0.6765, -0.4145, -0.9027,\n",
      "         -0.7398, -0.1770,  0.9421,  0.0217,  0.9107,  0.3187,  0.8872, -0.6592,\n",
      "         -0.5127, -0.1378,  2.4585, -0.6921, -1.4286,  0.6600,  0.5213,  0.9789,\n",
      "         -0.2304,  0.9187, -0.4171, -0.7016,  1.4888, -0.2203, -0.8421, -2.0081,\n",
      "          0.2840, -0.5002,  1.2553, -0.3851, -0.0655,  0.7874,  1.8405, -1.0688,\n",
      "         -0.6635,  1.5084,  0.1818,  0.5969,  1.6600, -0.3256, -1.0711, -0.9827,\n",
      "         -1.6477,  0.9321,  0.4239, -0.4546,  0.3871,  0.2427, -2.1464, -0.8586,\n",
      "          1.3566, -0.9797,  0.9973, -0.2456,  1.6298, -0.6677, -1.2457,  0.7792,\n",
      "         -0.2317, -0.2419,  1.4567,  0.0817, -0.1062, -0.6798, -0.7621,  0.1394,\n",
      "          1.8282, -0.6867,  0.6894, -0.3227, -1.4762, -0.7650, -1.7895, -1.7102,\n",
      "          1.3472, -1.2569, -1.0840,  0.5527,  0.2508, -1.3422,  0.7743,  1.1883,\n",
      "         -0.0483, -0.6589, -0.1038,  1.1571,  0.8177, -2.1923,  1.6667,  0.5801,\n",
      "          1.1205,  0.7923,  0.3245, -1.9914, -0.5902,  0.4578,  0.3590,  2.1062,\n",
      "         -0.1796, -0.1106,  0.1662, -0.1436, -0.8147,  0.5969, -0.4943,  0.0618,\n",
      "         -0.0097,  1.3726, -0.1758,  1.2559,  1.0264, -0.2395,  1.1915,  1.5418,\n",
      "          1.6222, -0.2900,  0.4573,  0.3903, -0.1773, -0.7980,  0.6356, -0.1418,\n",
      "         -0.6189,  0.8017, -1.1620, -0.0486, -0.0485,  0.6088, -0.0352,  0.6012,\n",
      "          0.5390, -0.4528,  0.9192,  0.8272,  0.3000,  0.4812,  1.1186,  0.0215,\n",
      "         -1.0817, -1.5068,  0.6584,  0.2030, -0.2664,  1.0196, -1.3616, -1.5543,\n",
      "          1.4240,  0.8878, -0.0340, -2.5750, -2.6090,  0.1656,  0.9616,  0.5252,\n",
      "         -2.4149, -1.9915,  1.0953,  0.9952, -0.2112,  0.7993, -0.9326, -0.1816,\n",
      "         -0.8424,  0.6044,  1.5917, -1.4969,  1.4307,  2.0192,  2.0551, -0.5666,\n",
      "         -0.0697,  0.3332, -1.5929,  0.7521, -0.0395,  1.7304, -0.4245,  0.4265,\n",
      "         -1.1998, -0.6017,  2.2155,  0.4595, -0.0913,  0.9895,  1.1203,  1.0505,\n",
      "         -1.4598, -0.2440, -1.3899,  1.0795, -0.0424,  0.6475, -2.5374, -0.2405]],\n",
      "       device='cuda:0')\n",
      "y tensor([[-2.3410,  0.3402,  0.1163, -0.2642, -1.0643, -1.0357,  1.7048, -1.2061,\n",
      "         -2.7898, -0.6247, -1.8066,  0.2020,  1.1551,  0.6929,  0.1647, -0.0485,\n",
      "         -0.4090,  0.7043, -0.6973,  0.0906, -1.1043, -0.4508,  0.4380, -0.6216,\n",
      "         -0.6868, -0.5669, -0.0890,  0.6507, -1.4665,  1.8659, -0.0173,  1.9695,\n",
      "         -0.3290,  0.6349, -2.0433, -0.9278,  0.0726,  1.1114, -0.5945, -0.3694,\n",
      "          0.1532, -1.0616, -0.2788, -0.2109,  0.2103,  0.5312,  1.7730,  1.6481,\n",
      "          0.2457,  0.5774,  0.5848, -0.3414,  1.7143, -0.2499,  0.3110,  0.6545,\n",
      "          2.5340,  1.0580,  1.0543, -1.8411, -0.3170, -0.2639, -0.7125,  1.5470,\n",
      "         -0.7141, -2.5324, -1.1406,  0.8956, -1.8177, -0.1478,  0.0646,  0.0417,\n",
      "          0.1234, -0.4232,  0.2918,  0.6973,  1.7472,  0.8229,  0.0082, -1.0829,\n",
      "          0.0291, -0.2864,  0.1601, -0.3978, -1.1001,  0.0291, -0.1172,  1.3732,\n",
      "         -0.6847,  0.1325,  1.2956,  0.6565, -0.1607, -0.3694, -0.0815, -0.8808,\n",
      "         -0.0509, -0.3021,  0.5710,  1.1896, -1.1815, -0.1508,  0.0866, -2.4449,\n",
      "         -1.5352, -1.1405, -0.5697,  1.3567,  0.1913,  0.0049,  2.0354, -2.1492,\n",
      "         -1.4776,  1.1221,  0.9153, -0.7932,  1.4041,  0.5357, -1.1957, -2.6526,\n",
      "          0.9382,  0.1953,  0.8212,  1.6663,  0.3497,  0.5875,  0.3436,  1.3150,\n",
      "         -0.3479, -0.9962,  1.7023,  0.5433,  1.0545,  0.7304, -0.2413,  0.8201,\n",
      "          0.6243,  0.3741, -0.4308, -1.1182, -1.2537,  2.0204, -1.2369,  1.1732,\n",
      "         -1.3044, -0.4172,  1.0047,  1.1248,  0.4471, -0.4563, -0.5062,  0.7756,\n",
      "         -1.4067,  0.0379,  0.5303, -0.6423, -1.6005, -2.4375,  1.0640, -1.9012,\n",
      "         -3.4950,  0.7551, -0.6738,  0.7668,  1.5051,  0.4652, -0.5840, -1.8244,\n",
      "         -0.6677, -0.8381,  0.6951, -1.1351,  0.9879,  0.3736, -0.3034, -0.9958,\n",
      "          1.1986, -0.5073, -0.7467, -2.2302, -0.4019, -1.5338,  2.1312,  0.2083,\n",
      "         -0.1974,  0.7459,  0.6819, -0.0155, -0.5210, -1.2381,  0.3101, -0.1743,\n",
      "         -1.6441,  0.9418, -1.2120,  0.7167, -0.0753, -1.3892,  0.5761, -0.4241,\n",
      "         -0.6725,  0.0916,  0.7021, -0.8027, -1.2219,  1.4538, -1.8760, -0.8914,\n",
      "          0.1032,  2.4115, -0.3234, -0.5974, -1.8550,  2.1201, -1.4888, -1.6765,\n",
      "          1.5242,  0.8047,  0.2461,  0.7058, -1.2435, -1.0595,  0.2954, -0.8096,\n",
      "         -0.5207, -0.4695,  0.0312,  0.0066,  0.0370, -0.1568,  0.0236, -1.6691,\n",
      "          0.4903,  0.2029,  1.0037,  0.8265,  0.4684,  1.2478, -0.5607, -0.8035,\n",
      "          0.6543,  1.8294, -0.9138,  0.3672, -1.0220, -0.6999,  0.9978, -0.8465,\n",
      "         -0.2692, -0.4425, -0.8805, -1.8813, -0.0420,  0.5182,  0.5768,  0.4867,\n",
      "          0.9015, -0.4472,  1.6278,  0.2855,  1.0245, -0.4331,  0.2108, -1.1709,\n",
      "         -1.1101,  1.1018, -0.1201,  1.9767,  1.0791, -2.2422, -0.3620, -0.3569,\n",
      "          0.5438,  1.0641,  0.6468, -1.3518, -0.4566, -0.3042,  1.1018,  1.1520,\n",
      "         -2.5810,  0.8165,  0.5289, -1.3527,  1.1138,  0.4288,  0.1507, -0.1516,\n",
      "         -0.5455,  0.4467, -0.2787,  2.3755, -1.0679,  0.7876,  0.1573, -0.2243,\n",
      "         -0.1426, -0.2651,  0.7835, -0.0432, -0.4054,  0.2663, -0.4641, -0.3622,\n",
      "         -1.4083,  0.0321,  0.3616, -0.8249,  0.9200,  0.1726,  1.4826,  0.5991,\n",
      "          0.6409, -0.8887,  1.0221, -0.8187,  0.6901,  0.3848, -0.1809, -0.3078,\n",
      "         -1.8283, -0.1912, -0.8513,  0.6225,  0.4458,  1.0565,  0.0864, -0.6812,\n",
      "         -1.7669,  1.5736, -0.4585, -0.7414,  0.2028, -0.2432, -1.4104, -0.4250,\n",
      "         -0.2626,  0.5916,  0.7497,  0.7797,  0.4233,  0.6338, -1.8845, -1.4200,\n",
      "          0.9786, -0.6665, -2.3229, -0.0921, -0.2078,  1.9204, -0.9532, -0.1165,\n",
      "          1.1428, -0.0717, -1.0335,  0.7000, -0.6207,  0.0943, -0.5124,  0.1820,\n",
      "          0.5684, -0.9350,  0.9253,  0.1802,  2.1804, -2.4996,  0.4499, -0.2888,\n",
      "          0.9173,  0.0202,  0.2621, -0.2417, -0.1272, -2.0194,  1.6499,  0.1309,\n",
      "          0.4016, -0.0417,  0.8330,  1.1601,  1.2773,  1.9158, -0.6391, -1.0555,\n",
      "          0.6769, -1.0936, -0.9223, -0.0859, -1.2649,  0.0856,  0.3668,  0.3867,\n",
      "         -0.1760, -1.4736, -0.3941, -1.2971, -0.7326, -1.7880, -1.8401,  2.1066,\n",
      "         -1.3106,  2.4478,  0.7099,  0.7070, -1.7998, -0.3961, -1.3742, -0.0870,\n",
      "         -0.4691,  0.5340,  0.0073,  2.4053, -0.7843, -0.9156, -1.5994, -0.8743,\n",
      "         -0.2889,  0.9666, -0.8710,  1.1297, -1.1163, -0.1443,  1.0297, -0.1899,\n",
      "          0.2416,  0.4915,  0.8218, -2.1912,  0.5948, -0.3926, -0.0302, -1.3466,\n",
      "          0.0412, -0.1668,  0.4040,  1.0425,  2.4800, -0.0132, -0.4830, -0.7265,\n",
      "          1.8021, -1.1125,  0.0307, -2.3077,  1.0033, -1.4895, -0.3924,  0.9687,\n",
      "          0.4582, -0.4897, -0.1588,  0.1036,  0.9165,  0.2792,  0.8106, -0.3872,\n",
      "         -1.1143,  0.2852,  0.4301,  0.1456, -0.1243, -0.2656,  0.4517, -0.0273,\n",
      "          1.0864,  1.1695, -1.3009,  1.6824,  2.8679,  0.7034,  0.8640, -0.7125,\n",
      "         -1.1512,  0.3070, -0.5144, -1.1754,  0.6795, -0.0861, -1.1693, -0.1328,\n",
      "         -1.0264,  1.5424, -0.8098, -0.2973, -0.0952,  0.3636,  0.2036,  0.9694,\n",
      "         -1.3018,  1.1674,  0.2577, -0.5438, -0.9034, -2.4994, -1.0665,  0.2502,\n",
      "          1.5249,  1.4636, -0.3934,  0.8425,  0.8753, -0.6857, -0.5146,  0.5454,\n",
      "          0.1156, -0.3480, -0.1588,  0.8303,  1.8366, -0.3260, -1.5160,  1.6990,\n",
      "          0.0585,  0.7976,  2.5055, -0.3170, -1.3901,  0.1378,  0.7125,  2.8524,\n",
      "         -1.1215, -0.4429, -0.6659,  0.4541,  0.2696,  0.2840,  1.7916,  1.4146,\n",
      "          0.7247, -3.2195,  2.0531,  0.2351, -0.5600, -0.5196,  2.1354, -0.5475,\n",
      "         -0.2345, -1.3022,  0.7508, -0.9030,  0.9009,  1.3176, -0.5801,  0.1510,\n",
      "         -1.0279,  0.9370,  0.8542, -0.1099,  0.4429,  0.3180, -0.5837,  0.5681,\n",
      "          0.9237,  0.4739, -0.5827,  0.8903, -0.2009, -0.4308, -0.4806,  0.2507,\n",
      "         -1.2584,  1.0193, -1.4237,  0.5953, -0.3951,  0.3388,  1.2203,  0.1016,\n",
      "          0.4927,  0.1219,  1.7673, -0.5602,  1.9071,  1.8013,  1.8417,  0.7183,\n",
      "          0.2759,  0.8202, -0.1126, -0.4779, -0.1941, -0.0977, -1.0680,  1.7344,\n",
      "          0.1107, -0.3200,  1.4737, -0.0805, -1.0036,  0.6979, -0.4664, -0.8316,\n",
      "         -0.8449, -0.2010,  0.8360, -0.0114,  0.9800,  0.3497,  0.9292, -0.7011,\n",
      "         -0.4200, -0.1478,  2.4461, -0.7764, -1.5572,  0.6749,  0.5046,  1.0064,\n",
      "         -0.2769,  0.9962, -0.4072, -0.6905,  1.5457, -0.2074, -0.8411, -2.1175,\n",
      "          0.3081, -0.4299,  1.1828, -0.3609, -0.0397,  0.8042,  1.9005, -1.1922,\n",
      "         -0.7007,  1.4117,  0.1247,  0.5923,  1.6430, -0.2699, -1.0214, -1.0270,\n",
      "         -1.7666,  0.8986,  0.3453, -0.4662,  0.3802,  0.2200, -2.1528, -0.8847,\n",
      "          1.4318, -1.0404,  1.1267, -0.2974,  1.6693, -0.6792, -1.2582,  0.7125,\n",
      "         -0.2364, -0.3378,  1.4525, -0.0176, -0.2210, -0.7390, -0.8099,  0.1403,\n",
      "          1.8375, -0.6590,  0.6695, -0.3009, -1.3521, -0.7822, -1.6789, -1.6679,\n",
      "          1.3077, -1.1214, -1.1337,  0.6478,  0.2694, -1.2926,  0.8111,  1.1157,\n",
      "         -0.0255, -0.7627, -0.0724,  1.2416,  0.7489, -2.1570,  1.6171,  0.5550,\n",
      "          1.2722,  0.7626,  0.2910, -1.8182, -0.5032,  0.4643,  0.3524,  2.3187,\n",
      "         -0.1761, -0.0879,  0.1178, -0.1427, -0.8024,  0.6235, -0.5045,  0.0584,\n",
      "         -0.0287,  1.2889, -0.1379,  1.2458,  0.9996, -0.2172,  1.0429,  1.6722,\n",
      "          1.7996, -0.2495,  0.4706,  0.3914, -0.1501, -0.8123,  0.6022, -0.1026,\n",
      "         -0.7148,  0.8414, -1.2076, -0.0197, -0.0201,  0.6513,  0.0285,  0.6097,\n",
      "          0.4577, -0.4625,  1.0354,  0.8675,  0.3186,  0.4782,  1.3051,  0.0096,\n",
      "         -1.0276, -1.4712,  0.7197,  0.1494, -0.2920,  1.1000, -1.3978, -1.5784,\n",
      "          1.4536,  0.9560, -0.0758, -2.4700, -2.6315,  0.1401,  0.9015,  0.5980,\n",
      "         -2.4091, -2.0275,  1.0698,  0.9905, -0.2654,  0.8582, -1.0300, -0.1257,\n",
      "         -0.9100,  0.5225,  1.5268, -1.4232,  1.4458,  2.0024,  1.9689, -0.5673,\n",
      "          0.0028,  0.3337, -1.5098,  0.7501, -0.1004,  1.6848, -0.4024,  0.4699,\n",
      "         -1.1684, -0.5274,  2.3493,  0.4431, -0.0905,  0.9749,  1.1989,  1.0176,\n",
      "         -1.6083, -0.1920, -1.5414,  1.1414, -0.1156,  0.6264, -2.5755, -0.2275]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    sample = net.forward(torch.randn(1, 784).to(device))\n",
    "\n",
    "sample = sample.view(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = net.inverse(torch.zeros(2, 784).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1069, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = iter(mnist_validation_loader).next()\n",
    "images = images.to(device).view(images.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = net.inverse(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2614, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[-0.7472, -0.0758, -0.5642,  ...,  0.2531, -0.2764, -1.0020],\n",
      "        [-0.2362, -2.2799,  1.1616,  ...,  0.7508, -0.1059,  0.6870],\n",
      "        [ 0.0248, -0.3227,  0.1708,  ...,  0.2416,  0.8022, -1.0866],\n",
      "        ...,\n",
      "        [ 2.3872,  0.6695,  0.3089,  ...,  0.3091, -1.3852, -0.9130],\n",
      "        [-0.2971, -0.6510,  1.6115,  ..., -0.1845, -0.8827, -1.3925],\n",
      "        [ 0.1186, -0.5456, -1.4667,  ...,  0.8036, -1.7854, -0.0812]],\n",
      "       device='cuda:0')\n",
      "y tensor([[-7.4717e-01, -7.5782e-02, -5.6419e-01,  ...,  6.4389e+05,\n",
      "         -2.4516e+06, -8.3379e+05],\n",
      "        [-2.3620e-01, -2.2799e+00,  1.1616e+00,  ...,  4.6392e+07,\n",
      "         -2.0941e+06,  3.0140e+07],\n",
      "        [ 2.4804e-02, -3.2266e-01,  1.7075e-01,  ...,  1.7382e+08,\n",
      "          4.0221e+08, -1.1127e+09],\n",
      "        ...,\n",
      "        [ 2.3872e+00,  6.6952e-01,  3.0893e-01,  ...,  1.6355e+06,\n",
      "         -2.9736e+06, -1.6499e+04],\n",
      "        [-2.9712e-01, -6.5097e-01,  1.6115e+00,  ..., -7.1185e+06,\n",
      "         -1.9705e+09, -9.2533e+06],\n",
      "        [ 1.1859e-01, -5.4559e-01, -1.4667e+00,  ...,  2.9053e+06,\n",
      "         -1.5376e+06, -2.1011e+03]], device='cuda:0')\n",
      "x tensor([[-8.3379e+05, -2.4516e+06,  6.4389e+05,  ..., -5.6419e-01,\n",
      "         -7.5782e-02, -7.4717e-01],\n",
      "        [ 3.0140e+07, -2.0941e+06,  4.6392e+07,  ...,  1.1616e+00,\n",
      "         -2.2799e+00, -2.3620e-01],\n",
      "        [-1.1127e+09,  4.0221e+08,  1.7382e+08,  ...,  1.7075e-01,\n",
      "         -3.2266e-01,  2.4804e-02],\n",
      "        ...,\n",
      "        [-1.6499e+04, -2.9736e+06,  1.6355e+06,  ...,  3.0893e-01,\n",
      "          6.6952e-01,  2.3872e+00],\n",
      "        [-9.2533e+06, -1.9705e+09, -7.1185e+06,  ...,  1.6115e+00,\n",
      "         -6.5097e-01, -2.9712e-01],\n",
      "        [-2.1011e+03, -1.5376e+06,  2.9053e+06,  ..., -1.4667e+00,\n",
      "         -5.4559e-01,  1.1859e-01]], device='cuda:0')\n",
      "y tensor([[-8.3379e+05, -2.4516e+06,  6.4389e+05,  ...,        -inf,\n",
      "                -inf,        -inf],\n",
      "        [ 3.0140e+07, -2.0941e+06,  4.6392e+07,  ...,         inf,\n",
      "                -inf,        -inf],\n",
      "        [-1.1127e+09,  4.0221e+08,  1.7382e+08,  ...,         inf,\n",
      "                -inf,         inf],\n",
      "        ...,\n",
      "        [-1.6499e+04, -2.9736e+06,  1.6355e+06,  ...,         inf,\n",
      "                 inf,         inf],\n",
      "        [-9.2533e+06, -1.9705e+09, -7.1185e+06,  ...,         inf,\n",
      "                -inf,        -inf],\n",
      "        [-2.1011e+03, -1.5376e+06,  2.9053e+06,  ...,        -inf,\n",
      "                -inf,         inf]], device='cuda:0')\n",
      "x tensor([[       -inf,        -inf,        -inf,  ...,  6.4389e+05,\n",
      "         -2.4516e+06, -8.3379e+05],\n",
      "        [       -inf,        -inf,         inf,  ...,  4.6392e+07,\n",
      "         -2.0941e+06,  3.0140e+07],\n",
      "        [        inf,        -inf,         inf,  ...,  1.7382e+08,\n",
      "          4.0221e+08, -1.1127e+09],\n",
      "        ...,\n",
      "        [        inf,         inf,         inf,  ...,  1.6355e+06,\n",
      "         -2.9736e+06, -1.6499e+04],\n",
      "        [       -inf,        -inf,         inf,  ..., -7.1185e+06,\n",
      "         -1.9705e+09, -9.2533e+06],\n",
      "        [        inf,        -inf,        -inf,  ...,  2.9053e+06,\n",
      "         -1.5376e+06, -2.1011e+03]], device='cuda:0')\n",
      "y tensor([[-inf, -inf, -inf,  ...,  nan,  nan,  nan],\n",
      "        [-inf, -inf,  inf,  ...,  nan,  nan,  nan],\n",
      "        [ inf, -inf,  inf,  ...,  nan,  nan,  nan],\n",
      "        ...,\n",
      "        [ inf,  inf,  inf,  ...,  nan,  nan,  nan],\n",
      "        [-inf, -inf,  inf,  ...,  nan,  nan,  nan],\n",
      "        [ inf, -inf, -inf,  ...,  nan,  nan,  nan]], device='cuda:0')\n",
      "x tensor([[ nan,  nan,  nan,  ..., -inf, -inf, -inf],\n",
      "        [ nan,  nan,  nan,  ...,  inf, -inf, -inf],\n",
      "        [ nan,  nan,  nan,  ...,  inf, -inf,  inf],\n",
      "        ...,\n",
      "        [ nan,  nan,  nan,  ...,  inf,  inf,  inf],\n",
      "        [ nan,  nan,  nan,  ...,  inf, -inf, -inf],\n",
      "        [ nan,  nan,  nan,  ..., -inf, -inf,  inf]], device='cuda:0')\n",
      "y tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    print(net.forward(torch.randn(10, 784).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s tensor([[2.5957, 2.3383, 1.6443,  ..., 2.8788, 2.3988, 2.2481],\n",
      "        [3.3695, 2.9178, 1.7075,  ..., 3.5182, 2.6462, 3.9164],\n",
      "        [3.2878, 2.2820, 1.7664,  ..., 3.2280, 3.2903, 2.9567],\n",
      "        ...,\n",
      "        [3.2220, 2.1233, 1.5953,  ..., 2.9834, 2.0975, 2.1046],\n",
      "        [2.5063, 2.7136, 1.2357,  ..., 2.8135, 1.8542, 2.5172],\n",
      "        [3.1118, 2.9247, 1.3923,  ..., 2.0094, 2.2580, 2.2381]],\n",
      "       device='cuda:0')\n",
      "s tensor([[4.0390, 4.3636, 4.6937,  ..., 4.2226, 2.7556, 4.7394],\n",
      "        [4.6759, 3.6420, 3.1555,  ..., 3.2607, 3.4930, 3.2608],\n",
      "        [4.7570, 2.9147, 2.4470,  ..., 4.0140, 2.3988, 6.5281],\n",
      "        ...,\n",
      "        [6.3069, 5.0770, 5.8130,  ..., 3.3958, 5.2876, 4.5385],\n",
      "        [2.7821, 2.9965, 4.5675,  ..., 3.9526, 2.6341, 4.7032],\n",
      "        [4.9012, 4.5476, 4.7520,  ..., 1.8456, 2.9119, 2.5863]],\n",
      "       device='cuda:0')\n",
      "s tensor([[ 4.1019,  2.5510,  2.1366,  ...,  6.5113,  6.4442,  5.5103],\n",
      "        [ 3.1148,  3.6652,  2.2243,  ...,  5.5825,  7.3824,  5.1114],\n",
      "        [ 3.9139,  3.7440,  2.9401,  ...,  8.3827, 10.4969,  6.9609],\n",
      "        ...,\n",
      "        [ 3.1081,  2.7973,  1.6253,  ...,  4.7558,  6.0332,  4.4838],\n",
      "        [ 2.9567,  2.7256,  1.7595,  ...,  4.0936,  5.2366,  3.9261],\n",
      "        [ 3.7016,  3.6244,  2.0357,  ...,  5.6105,  6.7532,  3.8158]],\n",
      "       device='cuda:0')\n",
      "s tensor([[ 7.6529,  3.5865,  4.8125,  ...,  7.3794, 10.9543,  4.0455],\n",
      "        [ 6.7251,  4.8059,  3.8808,  ...,  6.6540,  9.7718,  5.4495],\n",
      "        [ 5.3957,  3.1367,  2.7796,  ...,  2.5082,  5.1065,  3.3555],\n",
      "        ...,\n",
      "        [ 9.1038,  6.9690,  6.5885,  ...,  9.2594, 17.6044,  6.1852],\n",
      "        [10.9911,  6.8500,  4.3200,  ...,  8.7686,  9.4120,  5.6623],\n",
      "        [13.6944,  5.6064,  9.1023,  ...,  7.9993, 19.4562,  6.3057]],\n",
      "       device='cuda:0')\n",
      "(tensor([[ 0.0566,  0.0370,  0.0931,  ...,  0.1341,  0.1130,  0.3910],\n",
      "        [ 0.0260,  0.1237,  0.0001,  ...,  0.1940,  0.0916,  0.1911],\n",
      "        [-0.0705,  0.1049,  0.0932,  ...,  0.5368,  0.1068,  0.2040],\n",
      "        ...,\n",
      "        [ 0.1966,  0.1784,  0.0973,  ...,  0.0863,  0.0599,  0.1801],\n",
      "        [-0.0334, -0.0331,  0.0745,  ...,  0.1408,  0.0508,  0.2530],\n",
      "        [ 0.0386,  0.0391, -0.0800,  ...,  0.3316,  0.0855,  0.1834]],\n",
      "       device='cuda:0'), tensor([2712.8291, 2719.6902, 2582.9858, 2563.6707, 2419.2046, 2631.6335,\n",
      "        2851.7449, 2834.9866, 2616.0981, 2809.2346], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    print(net.inverse(torch.randn(10, 784).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7984,  0.8220,  0.6758,  1.4888, -0.0109, -0.7165, -1.4376,  1.3308,\n",
       "         0.6279, -0.8497,  0.6294,  0.5295,  1.2492,  0.0774, -0.0492,  1.0979,\n",
       "        -0.6764, -0.1201,  1.6719, -0.0995, -1.3592,  0.0114, -0.0487, -0.6956,\n",
       "         1.8140,  0.1182,  0.8033,  0.5284, -0.4588, -1.5489,  0.3645,  1.1177,\n",
       "        -0.5079, -0.3632, -1.6534,  0.8664, -0.8022,  1.3004,  0.1976,  0.1372,\n",
       "         0.2193,  1.7813, -1.7160,  0.4822, -0.1676,  0.8803, -0.5615,  0.0384,\n",
       "        -1.4392, -0.3056, -0.6186, -0.6356, -0.9583, -0.2932, -0.2989,  0.4327,\n",
       "         0.4273,  0.2716, -0.2579, -0.2603, -0.0427, -1.7424, -0.5800,  0.8615,\n",
       "         0.7566, -0.2605,  0.6372,  2.6446, -1.9264,  0.7857, -0.2589, -1.2601,\n",
       "         0.8287,  0.7230, -0.5182,  0.6486, -0.9256, -1.5446, -0.0730, -2.2513,\n",
       "         0.7509, -0.1070, -0.3396,  0.9466,  0.7164, -0.7586, -1.3994, -1.4052,\n",
       "        -0.4959,  1.3666,  0.0199, -0.2255,  0.2687, -0.1524,  1.3925, -0.0895,\n",
       "        -1.8163,  0.0826,  0.7276, -0.5768, -0.2058,  0.0610, -0.2996, -1.0431,\n",
       "         0.6629, -0.5670,  1.0711, -0.6855, -0.2067, -1.0361,  0.9012, -0.0130,\n",
       "         0.4856,  0.5236, -0.9298, -0.5884, -0.9890, -0.1611, -0.2117,  1.0809,\n",
       "        -0.8747, -1.1985, -0.3044,  2.0188,  0.2470,  0.1384,  0.8403, -0.6146,\n",
       "        -1.4342,  0.5148,  1.2079, -0.7114, -0.4249,  1.6904, -0.4607, -1.6948,\n",
       "         0.1348,  2.2807,  0.0549,  1.5064,  0.7941,  0.3847,  0.6325, -0.6352,\n",
       "        -0.8714,  0.5586, -0.3353, -0.0783, -1.3694,  0.6416, -0.0111, -0.3768,\n",
       "         0.0581,  1.6233,  0.0187,  0.2814,  0.6206,  0.1315,  0.6812,  0.9888,\n",
       "        -1.3821,  0.8100,  0.0299, -0.7429,  1.5592,  0.3669, -2.2661, -0.8936,\n",
       "        -0.9281,  1.4433,  0.9453,  1.9137, -1.8156,  1.1264, -2.1300,  1.7918,\n",
       "        -0.1932,  1.8636, -0.7707, -0.5773,  2.5436,  0.0222,  0.3639,  1.4853,\n",
       "        -0.2317,  0.9623,  0.8242, -0.5797,  0.0911,  0.4354, -1.1600, -0.7780,\n",
       "         0.7823, -0.7559,  0.1819, -0.4158,  0.3767, -1.3963, -2.2672,  0.0333,\n",
       "         0.8587,  0.1089,  1.0695,  0.4136,  0.9187, -0.0002, -0.6108, -0.7144,\n",
       "         0.3375,  1.8122, -0.2409, -0.9298, -1.2299, -0.8787, -1.0253, -1.1401,\n",
       "         1.3981, -0.9239, -0.2725,  0.0685, -0.1599,  1.5716,  0.6632,  2.3812,\n",
       "         0.6696, -0.8845,  1.1263,  0.6379, -1.7005,  0.1274, -1.9793,  0.9306,\n",
       "         0.2850,  0.3471, -1.2828, -1.1537,  0.6988,  0.4535, -1.3177,  0.6927,\n",
       "        -0.2407, -0.2180,  1.5713, -0.2813, -0.5206, -0.8496,  0.6300, -0.6579,\n",
       "         1.0548,  0.5042,  0.1680,  0.8444, -0.0182, -0.8899, -1.3538, -0.0267,\n",
       "        -0.2481,  0.9462, -0.6860,  0.4300,  0.3909, -0.6324, -0.7010,  1.8212,\n",
       "        -0.1031, -1.2586,  0.8406,  0.5148, -0.0446,  0.3064, -1.4436,  0.0813,\n",
       "        -1.4388, -1.5883, -0.8565,  1.2376,  1.9395, -2.0054, -0.9459, -0.3989,\n",
       "        -0.8322,  0.5458,  0.3531, -0.4528, -0.3065,  1.4672,  0.3183,  0.9137,\n",
       "         0.2934, -0.0569, -1.8338,  0.4083, -0.3611,  0.4698,  0.0182, -0.2381,\n",
       "         1.7102, -1.5402, -1.3654, -1.4506, -0.5513, -1.0412, -2.1734,  1.6567,\n",
       "        -1.2675, -1.7600,  1.4435, -0.6802,  1.2398, -0.0902,  0.4261,  0.5538,\n",
       "         0.1441,  0.3106,  1.1907,  0.9246, -0.3476,  1.4018,  0.8082, -1.8581,\n",
       "        -0.3209,  0.8358, -0.2031, -1.1216,  1.8957,  2.2688, -0.6258, -1.1959,\n",
       "         1.3103,  0.6722, -0.3022,  0.7255, -1.1221,  0.3776,  0.8560,  0.7831,\n",
       "         0.4173, -1.1132,  0.9981, -0.2366, -1.8669,  0.8204,  0.1185, -0.4060,\n",
       "        -1.8376, -0.5750,  0.0292,  0.5006, -1.4397,  0.1885, -1.0138,  0.1734,\n",
       "         0.0416,  1.8764, -0.5215,  0.0758, -1.0336,  1.6296,  0.2239, -1.0871,\n",
       "        -0.7214, -1.5384,  0.4048,  0.3360, -0.0048, -0.8882, -0.8416, -0.5985,\n",
       "        -0.0741,  1.5018,  1.3636, -0.7243, -0.6299, -0.5224,  0.5089, -1.1820,\n",
       "        -0.6569, -1.6782,  1.7304,  0.1448, -0.1683,  0.2725, -2.8025, -0.6786,\n",
       "         0.1005,  1.7381, -0.3941, -0.6218, -0.9875, -1.9322, -1.7609, -0.8091,\n",
       "         1.5853, -0.9242,  0.1282,  0.4626,  0.1587, -1.6934, -0.1063,  0.3214,\n",
       "        -0.3538,  0.4981,  0.1467,  0.3361,  1.6148,  1.7050,  2.4024, -0.1936,\n",
       "        -0.0531,  0.3653,  0.2113,  0.3241,  0.5558, -0.8068, -0.1671, -0.1264,\n",
       "         0.3340, -1.4371, -0.2075,  0.7664,  0.0746,  0.8516,  0.7514, -0.6479,\n",
       "         0.2920, -0.8859,  1.8145,  0.8098,  0.6855, -0.6706,  1.5045,  0.6752,\n",
       "        -0.1250, -0.1128,  1.6199,  0.6314,  0.7035, -0.2219, -0.4490,  0.8032,\n",
       "         1.6650,  0.6369, -0.4262,  0.4785,  0.3220, -0.1247,  1.8032,  1.5584,\n",
       "         0.2038,  0.0310,  0.2894,  0.4099, -2.3073,  1.2730,  1.8715, -0.3056,\n",
       "        -0.9259, -0.5686, -1.1385, -1.1203,  0.0065, -0.6164, -0.3360, -0.9539,\n",
       "        -0.2951,  0.8707,  0.0584, -0.5450,  0.0442,  0.3324, -0.3258,  0.5513,\n",
       "         0.4829,  0.4455,  0.2544, -1.6084,  1.3377, -1.0775,  1.6858,  0.5054,\n",
       "         0.2931, -1.3495,  0.3960, -0.7643, -0.6066,  0.2069, -0.3909,  1.3502,\n",
       "        -0.0616,  0.4864,  1.2283, -0.3981, -1.0105,  1.0229,  0.0211, -0.4894,\n",
       "        -1.1055,  0.8051,  0.5486, -0.8690, -1.2381,  1.1005, -1.1259, -0.2130,\n",
       "        -1.0045,  0.4433,  2.0126,  0.1550,  0.1224,  1.4793,  0.3104, -0.3384,\n",
       "        -1.0504,  0.2493, -1.4202,  0.1470, -0.6358,  1.0086,  0.5835,  0.0020,\n",
       "         0.6399, -0.2638,  0.4459,  0.6275, -0.1081,  0.6916, -1.0678, -1.2695,\n",
       "        -0.0248,  0.9435, -1.0509,  0.1258, -0.1469,  0.5594, -1.5674,  0.5434,\n",
       "        -0.4033,  0.5693, -1.3893, -0.5196,  0.2204, -1.1591,  0.8777, -0.7072,\n",
       "         0.4884,  1.5860,  0.4234, -0.5036, -0.5976,  1.0856,  1.1653,  0.2229,\n",
       "        -0.4241, -0.6495, -1.6896, -1.1338,  0.4360, -0.4974, -0.4213, -0.9215,\n",
       "        -0.4233, -1.4217,  1.3585, -0.0437, -1.5515,  0.5641,  0.4921, -0.8183,\n",
       "        -1.0570, -2.8214, -0.4880, -1.0417,  0.4295,  0.5147, -0.4712, -0.5457,\n",
       "         0.1369,  1.1440,  1.4816,  0.0556,  1.2067, -2.0579,  0.4908, -1.3711,\n",
       "        -0.9123,  0.0256,  3.0221,  0.0996, -1.7428, -0.2956,  0.7320,  0.2628,\n",
       "         0.5193, -0.0985, -0.3886, -0.4677,  0.5969,  0.8596, -2.0629, -0.2500,\n",
       "        -0.9115,  0.2326, -1.9403, -1.0231, -0.6192, -0.6661, -0.6309, -0.1823,\n",
       "        -2.6690,  0.1428,  0.2286,  0.5618,  0.9310,  1.1979, -2.0216, -0.5350,\n",
       "         0.4401,  0.8459,  0.9937,  0.5284,  0.6258,  1.2238, -0.3549, -0.7708,\n",
       "        -1.3075,  1.1504,  0.6623, -0.4152,  0.4297, -0.0794,  0.6401, -2.2537,\n",
       "        -1.1679,  1.5633, -0.7034,  0.1299,  0.4823, -0.0068,  0.3155, -0.5231,\n",
       "        -0.1464,  0.3316,  1.5994, -0.4717, -0.6251, -0.4644, -0.4053, -1.2914,\n",
       "        -0.7753, -1.8862, -1.2337, -0.7207,  0.0648,  1.0393, -1.2686,  0.5431,\n",
       "         0.0462, -0.5550, -1.3506,  0.1624, -0.1726,  1.8045,  1.1827, -1.5705,\n",
       "        -0.9697,  0.3984, -0.4037, -0.4323, -1.3511,  0.5433, -0.2760,  0.0898,\n",
       "        -1.1536, -0.3976,  0.3470, -0.5394, -1.5497,  0.7343, -0.1110, -0.5422,\n",
       "        -0.5874,  0.7067,  1.6279, -1.7271, -2.3901,  0.4179, -0.7005, -0.7259,\n",
       "         0.7483, -0.8205,  1.3958,  0.8549,  1.0649,  0.5440, -1.4132, -1.3192,\n",
       "         1.0650, -0.1001,  0.2856, -0.4954, -0.3392, -0.2011, -1.9179,  0.6012,\n",
       "         0.0893,  0.2513,  1.4142,  0.3982,  0.3080, -0.4536,  0.8057, -1.2047,\n",
       "         1.3261,  1.9736,  1.5910,  0.3591, -1.5646, -1.0711,  1.6959,  0.2886,\n",
       "        -0.1183, -1.6166,  2.0568, -0.1000,  1.8893,  0.4911, -1.0536,  0.9111,\n",
       "         0.9869, -0.1160, -1.7895,  1.3276,  0.0690, -0.3240, -0.7827, -0.9696,\n",
       "         1.4266,  2.1871,  0.0622, -0.1394, -1.4058,  1.1778, -0.3305, -0.1051,\n",
       "         0.0963,  0.7141, -1.5207,  1.4249, -0.0050,  0.5460,  0.8022,  1.5090,\n",
       "         1.1710,  0.2589, -0.9388, -1.8343, -0.3174,  0.4917, -0.2962, -0.8916,\n",
       "         0.8610,  0.2946,  1.8247, -0.2133,  0.2725,  0.6246, -0.7450,  1.1583,\n",
       "        -0.0715, -0.4152,  0.9937,  0.6485, -0.5240,  1.2918,  0.8985,  0.0588,\n",
       "         1.1072, -0.9348,  1.5708,  0.8861,  0.8403,  0.4895,  0.0747, -0.0896],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(64,784).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(64,784).mean(dim=0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(64,784).var(dim=0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(64,784) / torch.zeros(64,784).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
