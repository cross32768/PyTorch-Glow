{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.0.0\n",
      "torchvision verseion: 0.2.1\n",
      "Is GPU avaibale: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('torchvision verseion:', torchvision.__version__)\n",
    "print('Is GPU avaibale:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings (バッチサイズとデバイス)\n",
    "batchsize = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of training data: 60000\n",
      "the number of validation data: 10000\n"
     ]
    }
   ],
   "source": [
    "# データセットの準備\n",
    "# Tensorにしつつ、 (-1 ~ 1)の範囲に正規化\n",
    "tf = transforms.Compose([transforms.ToTensor(), \n",
    "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# データセットをロード(今回はMNIST)\n",
    "# 本当はtraining data, validation data, test dataに分けるべきだが、今回は簡便のため2つに分ける.\n",
    "mnist_train = datasets.MNIST(root = '../../data/MNIST',\n",
    "                                 train = True,\n",
    "                                 transform = tf,\n",
    "                                 download = False)\n",
    "mnist_validation = datasets.MNIST(root = '../../data/MNIST',\n",
    "                                      train = False,\n",
    "                                      transform = tf)\n",
    "\n",
    "# データローダーを作成\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size = batchsize, shuffle = True)\n",
    "mnist_validation_loader = DataLoader(mnist_validation, batch_size = batchsize, shuffle = False)\n",
    "\n",
    "print('the number of training data:', len(mnist_train))\n",
    "print('the number of validation data:', len(mnist_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7523fbf828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可視化のための関数\n",
    "def show_image(img):\n",
    "    npimg = img.numpy() * 0.5 + 0.5\n",
    "    plt.figure(figsize = (5, 5))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "images, labels = iter(mnist_train_loader).next()\n",
    "# 25画像をまとめて表示\n",
    "show_image(make_grid(images[:25], nrow=5, padding=1))\n",
    "# 画像の形状（channel, height, width）\n",
    "print(images[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actnormの実装\n",
    "class ActNorm2d(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(ActNorm2d, self).__init__()\n",
    "        size = [1, num_features, 1, 1]\n",
    "        self.register_parameter('bias', nn.Parameter(torch.zeros(*size)))\n",
    "        self.register_parameter('log_s', nn.Parameter(torch.zeros(*size)))\n",
    "        self.inited = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.inited:\n",
    "            self.initialize_parameters(x)\n",
    "        \n",
    "        z = torch.exp(self.log_s) * x + self.bias\n",
    "        # z = (x + self.bias) * torch.exp(self.log_s)\n",
    "        log_det_jacobian = self.calculate_log_det_jacobian(x)\n",
    "        return z, log_det_jacobian\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        x = (z - self.bias) * torch.exp(-self.log_s)\n",
    "        return x\n",
    "\n",
    "    def calculate_log_det_jacobian(self, x):\n",
    "        h, w = x.size(2), x.size(3)\n",
    "        return h * w * torch.sum(self.log_s)\n",
    "    \n",
    "    def initialize_parameters(self, first_minibatch_x):\n",
    "        # cloneいるか？ .detachこれでいい？\n",
    "        bias = -1.0 * self.multidim_mean(first_minibatch_x.clone().detach(), dims=[0, 2, 3])\n",
    "        var_s = self.multidim_mean((first_minibatch_x.clone().detach() + bias) ** 2, dims=[0, 2, 3])\n",
    "        log_s = torch.log(1 / (torch.sqrt(var_s) + 1e-6))\n",
    "        \n",
    "        self.bias.data.copy_(bias.data)\n",
    "        self.log_s.data.copy_(log_s.data)\n",
    "        \n",
    "        self.inited = True\n",
    "            \n",
    "    def multidim_mean(self, tensor, dims):\n",
    "        dims = sorted(dims)\n",
    "        for d in dims:\n",
    "            tensor = tensor.mean(dim=d, keepdim=True)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invertible 1x1 convolutionの実装\n",
    "class Invertible1x1Conv2d(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Invertible1x1Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(num_features, num_features, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        W = torch.qr(torch.FloatTensor(num_features, num_features).normal_())[0]\n",
    "        \n",
    "        if torch.det(W) < 0:\n",
    "            W[:,0] = -W[:,0]\n",
    "        \n",
    "        self.conv.weight.data = W.view(num_features, num_features, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.conv(x)\n",
    "        log_det_jacobian = self.calculate_log_det_jacobian(x)\n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def inverse(self, z):\n",
    "        if not hasattr(self, 'W_inverse'):\n",
    "            W = self.conv.weight.squeeze()\n",
    "            W_inverse = W.inverse()\n",
    "            # W_inverse = torch.autograd.Variable(W_inverse.view(*W_inverse.size(), 1, 1)) # Variableいるか？\n",
    "            self.W_inverse = W_inverse.view(*W_inverse.size(), 1, 1)\n",
    "        x = F.conv2d(z, self.W_inverse, bias=None, stride=1, padding=0)\n",
    "        return x\n",
    "        \n",
    "    def calculate_log_det_jacobian(self, x):\n",
    "        W = self.conv.weight.squeeze()\n",
    "        h, w = x.size(2), x.size(3)\n",
    "        return h * w * torch.logdet(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coupling layerで使われるCNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, affine=True):\n",
    "        super(CNN, self).__init__()\n",
    "        self.affine = affine\n",
    "        if affine:\n",
    "            n_out = n_in*2\n",
    "        else:\n",
    "            n_out = n_in\n",
    "            \n",
    "        self.cv1 = nn.Conv2d(n_in, n_hidden, kernel_size=3, stride=1, padding=1)\n",
    "        self.cv2 = nn.Conv2d(n_hidden, n_hidden, kernel_size=1, stride=1, padding=0)\n",
    "        self.cv3 = nn.Conv2d(n_hidden, n_out, kernel_size=3, stride=1, padding=1)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, CNN_input):\n",
    "        out = F.relu(self.cv1(CNN_input))\n",
    "        out = F.relu(self.cv2(out))\n",
    "        if self.affine:\n",
    "            out = self.cv3(out)\n",
    "            n_half = int(out.size(1) / 2)\n",
    "            log_s = torch.tanh(out[:,:n_half,:,:])\n",
    "            bias = out[:,n_half:,:,:]\n",
    "            return [log_s, bias]\n",
    "        else:\n",
    "            bias = self.cv3(out)\n",
    "            return bias\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.cv1.weight.data.normal_(0, 0.05)\n",
    "        self.cv1.bias.data.zero_()\n",
    "        self.cv2.weight.data.normal_(0, 0.05)\n",
    "        self.cv2.bias.data.zero_()\n",
    "        self.cv3.weight.data.zero_()\n",
    "        self.cv3.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coupling layerの実装\n",
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, num_features, n_hidden, affine=True):\n",
    "        super(CouplingLayer, self).__init__()\n",
    "        \n",
    "        assert num_features % 2 == 0\n",
    "        self.n_half = int(num_features / 2)\n",
    "        self.affine = affine\n",
    "        \n",
    "        self.CNN = CNN(self.n_half, n_hidden, affine)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x_a = x[:,:self.n_half,:,:]\n",
    "        x_b = x[:,self.n_half:,:,:]\n",
    "        \n",
    "        CNN_output = self.CNN(x_a)\n",
    "        \n",
    "        if self.affine:\n",
    "            log_s = CNN_output[0]\n",
    "            bias = CNN_output[1]\n",
    "            z_b = torch.exp(log_s) * x_b + bias\n",
    "            # z_b = (x_b + bias) * torch.exp(log_s)\n",
    "        else:\n",
    "            log_s = None\n",
    "            z_b = x_b + CNN_output\n",
    "            \n",
    "        z = torch.cat([x_a, z_b], dim=1)\n",
    "        log_det_jacobian = self.calculate_log_det_jacobian(log_s)\n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def inverse(self, z):\n",
    "        z_a = z[:,:self.n_half,:,:]\n",
    "        z_b = z[:,self.n_half:,:,:]\n",
    "        \n",
    "        CNN_output = self.CNN(z_a)\n",
    "        \n",
    "        if self.affine:\n",
    "            log_s = CNN_output[0]\n",
    "            bias = CNN_output[1]\n",
    "            x_b = (z_b - bias) * torch.exp(-log_s)\n",
    "        else:\n",
    "            x_b = z_b - CNN_output\n",
    "            \n",
    "        x = torch.cat([z_a, x_b], dim=1)\n",
    "        return x\n",
    "        \n",
    "    def calculate_log_det_jacobian(self, log_s):\n",
    "        if self.affine:\n",
    "            return torch.sum(log_s)\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上３つをまとめたFlow\n",
    "class StepofFlow(nn.Module):\n",
    "    def __init__(self, num_features, n_hidden, affine=True):\n",
    "        super(StepofFlow, self).__init__()\n",
    "        self.actnorm = ActNorm2d(num_features)\n",
    "        self.invertible1x1conv = Invertible1x1Conv2d(num_features)\n",
    "        self.couplinglayer = CouplingLayer(num_features, n_hidden, affine)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, ldj_actnorm  = self.actnorm(x)\n",
    "        x, ldj_1x1conv  = self.invertible1x1conv(x)\n",
    "        z, ldj_coupling = self.couplinglayer(x)\n",
    "        log_det_jacobian = ldj_actnorm + ldj_1x1conv + ldj_coupling\n",
    "        return z, log_det_jacobian\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        z = self.couplinglayer.inverse(z)\n",
    "        z = self.invertible1x1conv.inverse(z)\n",
    "        x = self.actnorm.inverse(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glow本体\n",
    "class Glow(nn.Module):\n",
    "    def __init__(self, L, K, num_input_features, n_hidden_list, affine=True):\n",
    "        super(Glow, self).__init__()\n",
    "        self.L = L\n",
    "        self.K = K\n",
    "        \n",
    "        num_features = num_input_features\n",
    "        assert len(n_hidden_list) == L*K\n",
    "        \n",
    "        self.flow = torch.nn.ModuleList()\n",
    "        for l in range(L):\n",
    "            # squeeze\n",
    "            num_features *= 4\n",
    "            for k in range(K):\n",
    "                # step of flow\n",
    "                self.flow.append(StepofFlow(num_features, int(n_hidden_list[l*K + k]), affine))\n",
    "            # split\n",
    "            num_features = num_features // 2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = []\n",
    "        log_det_jacobian = 0\n",
    "        \n",
    "        for l in range(self.L):\n",
    "            # squeeze\n",
    "            x = self.squeeze(x)\n",
    "            for k in range(self.K):\n",
    "                # step of flow\n",
    "                x, ldj = self.flow[l*self.K + k](x)\n",
    "                log_det_jacobian += ldj\n",
    "            # split\n",
    "            if l == self.L-1:\n",
    "                z.append(x.view(x.size(0), -1))\n",
    "            else:\n",
    "                z.append(x[:,:x.size(1)//2,:,:].view(x.size(0), -1))\n",
    "                x = x[:,x.size(1)//2:,:,:]\n",
    "        \n",
    "        z = torch.cat(z, dim=1)\n",
    "        if not hasattr(self, 'Z'):\n",
    "            batchsize, Z_dim = z.size()\n",
    "            self.Z = MultivariateNormal(torch.zeros(Z_dim).to(device), torch.eye(Z_dim).to(device))\n",
    "            self.last_z_shape = x.size()[1:]\n",
    "            \n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def inverse(self, z):\n",
    "        x_dim = self.last_z_shape[0] * self.last_z_shape[1] * self.last_z_shape[2]\n",
    "        for l in reversed(range(self.L)):\n",
    "            if l == self.L-1:\n",
    "                x = z[:,-x_dim:].view(-1, *self.last_z_shape)\n",
    "            else:\n",
    "                z_in = z[:,-x_dim*2:-x_dim]\n",
    "                x = torch.cat([z_in.view(*x.size()), x], dim = 1)\n",
    "                x_dim = x_dim*2\n",
    "                \n",
    "            for k in reversed(range(self.K)):\n",
    "                x = self.flow[l*self.K + k].inverse(x)\n",
    "                \n",
    "            x = self.unsqueeze(x)\n",
    "        return x\n",
    "                \n",
    "    def squeeze(self, x, factor=2):\n",
    "        batchsize, channels, height, width = x.size()\n",
    "        assert height % factor == 0\n",
    "        assert width % factor == 0\n",
    "        z = x.view(batchsize, channels, height // factor, factor, width // factor, factor)\n",
    "        z = z.permute(0, 1, 3, 5, 2, 4)\n",
    "        z = z.contiguous().view(batchsize, channels * factor**2, height // factor, width // factor)\n",
    "        return z\n",
    "    \n",
    "    def unsqueeze(self, z, factor=2):\n",
    "        batchsize, channels, height, width = z.size()\n",
    "        x = z.view(batchsize, channels // (factor**2), factor, factor, height, width)\n",
    "        x = x.permute(0, 1, 4, 2, 5, 3)\n",
    "        x = x.contiguous().view(batchsize, channels // (factor**2), height * factor, width * factor)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 302912\n"
     ]
    }
   ],
   "source": [
    "net = Glow(L=2, K=16, num_input_features=1, n_hidden_list=np.ones(2*16)*256, affine=True)\n",
    "net = net.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "n_epochs = 50\n",
    "save_image_interval = 2\n",
    "n_save_image = 25\n",
    "save_dir = '../../data/glow_MNIST/'\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('The number of parameters:', num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    net.train()\n",
    "    running_loss = 0\n",
    "    for sample_x, _ in train_loader:\n",
    "        sample_x = sample_x.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict_z, log_det_jacobian = net(sample_x)\n",
    "        loss = -1 * torch.mean(net.Z.log_prob(predict_z) + log_det_jacobian)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(validation_loader, epoch):\n",
    "    net.eval()\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sample_x, _ in validation_loader:\n",
    "            sample_x = sample_x.to(device)\n",
    "            \n",
    "            predict_z, log_det_jacobian = net(sample_x)\n",
    "            loss = -1 * torch.mean(net.Z.log_prob(predict_z) + log_det_jacobian)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if epoch % save_image_interval == 0:\n",
    "            sample_z = net.Z.sample((n_save_image,))\n",
    "            predict_x = net.inverse(sample_z)\n",
    "            save_image(predict_x.data.cpu(), '{}/epoch_{}.png'.format(save_dir, epoch), nrow=5)\n",
    "            \n",
    "    return running_loss / len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[ 0/ 2] train_nll:-464790.5329 validation_nll:-583435.7808\n",
      "epoch[ 1/ 2] train_nll:-590745.6308 validation_nll:-590057.7745\n"
     ]
    }
   ],
   "source": [
    "train_nll_list = []\n",
    "validation_nll_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_nll = train(mnist_train_loader)\n",
    "    validation_nll = validation(mnist_validation_loader, epoch)\n",
    "    \n",
    "    train_nll_list.append(train_nll)\n",
    "    validation_nll_list.append(validation_nll)\n",
    "    \n",
    "    print('epoch[%2d/%2d] train_nll:%1.4f validation_nll:%1.4f' % (epoch+1, n_epochs, train_nll, validation_nll))\n",
    "\n",
    "torch.save(net.state_dict(), save_dir + 'glow_model.pth')\n",
    "torch.save(optimizer.state_dict(), save_dir + 'glow_optimizer.pth')\n",
    "\n",
    "np.save(save_dir + 'train_nll_list.npy', np.array(train_nll_list))\n",
    "np.save(save_dir + 'validation_nll_list.npy', np.array(validation_nll_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
